{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://arxiv.org/pdf/1607.03290.pdf Automatic Bridge Bidding Using Deep Reinforcement Learning\n",
    " \n",
    " https://github.com/chihkuanyeh/Automatic-Bridge-Bidding-by-Deep-Reinforcement-Learning  Automatic-Bridge-Bidding-by-Deep-Reinforcement-Learning \n",
    " \n",
    " http://www.csie.ntu.edu.tw/~htlin/paper/doc/wscpii15bridgebid.pdf\n",
    " \n",
    " https://www.aliyun.com/zixun/wenji/1261456.html\n",
    " \n",
    " https://labrosa.ee.columbia.edu/cuneuralnet/yakovenko120215.pdf\n",
    " \n",
    " http://willtipton.com/coding/poker/2017/06/06/shove-fold-with-reinforcement-learning.html Playing a toy poker game with Reinforcement Learning\n",
    " \n",
    " \n",
    " https://github.com/ishikota/PyPokerEngine PyPokerEngine  德克萨斯扑克\n",
    " \n",
    " https://www.jianshu.com/p/7014c89abeea 用一个小游戏入门深度强化学习\n",
    " \n",
    " https://arxiv.org/pdf/1603.01121.pdf Deep Reinforcement Learning from Self-Play in Imperfect-Information Games\n",
    " \n",
    " https://www.leiphone.com/news/201606/5ekkj6w511ZK5yOW.html\n",
    " \n",
    " https://arxiv.org/pdf/1705.02955.pdf Safe and Nested Subgame Solving for Imperfect-Information Games\n",
    " \n",
    " https://sourceforge.net/projects/tgchanpoker/  python pock game\n",
    " \n",
    " https://www.data-blogger.com/2017/11/01/pokerbot-create-your-poker-ai-bot-in-python/\n",
    " \n",
    " https://poker.readthedocs.io/en/latest/  Poker package\n",
    " \n",
    " https://sourceforge.net/projects/simpybigtwo/ 扑克中的“大老二”  https://www.wikihow.com/Play-Big-Two\n",
    " \n",
    " https://www.datacamp.com/community/tutorials/python-probability-tutorial Analyzing Poker Hands with Python\n",
    " \n",
    " http://openbookproject.net/books/bpp4awd/ch08.html Card objects as an example.\n",
    " \n",
    " https://blog.csdn.net/wzebinbin/article/details/78299677 AlphaGo Zero论文中文版:\n",
    " \n",
    " https://cloud.tencent.com/developer/article/1051220  强化学习系统\n",
    " \n",
    " https://cloud.tencent.com/developer/article/1051227 强化学习系统\n",
    " \n",
    " http://tigerneil.github.io/2016/05/30/nsfp/ 不完全信息博弈中自我对弈的深度强化学习技术 \n",
    " \n",
    " https://blog.csdn.net/Luke__/article/details/53000497 扑克牌游戏出牌规则\n",
    " \n",
    " https://baike.baidu.com/item/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/5500990?fr=aladdin 贝尔曼方程 也被称作动态规划方程\n",
    " \n",
    " https://baike.baidu.com/item/%E7%BA%B3%E4%BB%80%E5%9D%87%E8%A1%A1/534868?fr=aladdin Nash平衡\n",
    " \n",
    " https://cloud.tencent.com/developer/article/1150412 Neural Fictitious Self Play——从博弈论到深度强化学习\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
