{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://arxiv.org/pdf/1607.03290.pdf Automatic Bridge Bidding Using Deep Reinforcement Learning\n",
    " \n",
    " https://gym.openai.com/docs/#available-environments 游戏环境\n",
    " \n",
    " https://web.stanford.edu/~surag/posts/alphazero.html A Simple Alpha(Go) Zero Tutorial\n",
    " \n",
    " https://github.com/LorenzoM1997/Deep-tic-tac-toe dqn tic-tac-toe\n",
    " \n",
    " https://github.com/narisan25/TTT-RL dqn tic-tac-toe jupyter notebook\n",
    " \n",
    " https://github.com/chihkuanyeh/Automatic-Bridge-Bidding-by-Deep-Reinforcement-Learning  Automatic-Bridge-Bidding-by-Deep-Reinforcement-Learning \n",
    " \n",
    " \n",
    " https://github.com/tansey/rl-tictactoe  tictactoe两人游戏\n",
    " \n",
    " https://www.cs.dartmouth.edu/~lorenzo/teaching/cs134/Archive/Spring2009/final/PengTao/final_report.pdf tictactoe\n",
    " \n",
    " \n",
    " http://www.csie.ntu.edu.tw/~htlin/paper/doc/wscpii15bridgebid.pdf\n",
    " \n",
    " https://www.aliyun.com/zixun/wenji/1261456.html\n",
    " \n",
    " https://arxiv.org/pdf/1807.01281.pdf Human-level performance in first-person multiplayer games with population-based deep reinforcement learning\n",
    " \n",
    " https://labrosa.ee.columbia.edu/cuneuralnet/yakovenko120215.pdf\n",
    " \n",
    " http://www.algorithmdog.com/drl 强化学习系列之九:Deep Q Network (DQN)\n",
    " \n",
    " https://zhuanlan.zhihu.com/p/27860621 DRL实战：用PyTorch 150行代码实现Advantage Actor-Critic玩CartPole\n",
    " \n",
    " https://zhuanlan.zhihu.com/p/40600485 最前沿：Meta Learning前沿进展扫描\n",
    " \n",
    " https://zhuanlan.zhihu.com/p/41223529 最前沿: Meta RL论文解读\n",
    " \n",
    " https://zhuanlan.zhihu.com/p/45845001 最前沿：用模仿学习来学习增强学习\n",
    " \n",
    " https://zhuanlan.zhihu.com/p/46059552 Meta Learning单排小教学\n",
    " \n",
    " https://www.zhihu.com/people/flood-sung/posts\n",
    " \n",
    " https://zhuanlan.zhihu.com/p/21547911 DQN的优化问题\n",
    " \n",
    " https://zhuanlan.zhihu.com/p/25302079 深度增强学习的Actor-Critic框架\n",
    " \n",
    " https://zhuanlan.zhihu.com/p/26882898  DRL之Policy Gradient, Deterministic Policy Gradient与Actor Critic\n",
    " \n",
    " https://wanjun0511.github.io/2017/11/05/DQN/ 强化学习—DQN算法原理详解\n",
    " \n",
    " https://zhuanlan.zhihu.com/p/21262246?refer=intelligentunit DQN 从入门到放弃1\n",
    " \n",
    " http://willtipton.com/coding/poker/2017/06/06/shove-fold-with-reinforcement-learning.html Playing a toy poker game with Reinforcement Learning\n",
    " \n",
    " https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/2-1-general-rl/ 入门教程\n",
    " \n",
    " https://github.com/ishikota/PyPokerEngine PyPokerEngine  德克萨斯扑克\n",
    " \n",
    " https://www.jianshu.com/p/7014c89abeea 用一个小游戏入门深度强化学习\n",
    " \n",
    " https://arxiv.org/pdf/1603.01121.pdf Deep Reinforcement Learning from Self-Play in Imperfect-Information Games\n",
    " \n",
    " https://www.leiphone.com/news/201606/5ekkj6w511ZK5yOW.html\n",
    " \n",
    " https://arxiv.org/pdf/1705.02955.pdf Safe and Nested Subgame Solving for Imperfect-Information Games\n",
    " \n",
    " https://sourceforge.net/projects/tgchanpoker/  python pock game\n",
    " \n",
    " https://www.data-blogger.com/2017/11/01/pokerbot-create-your-poker-ai-bot-in-python/\n",
    " \n",
    " https://poker.readthedocs.io/en/latest/  Poker package\n",
    " \n",
    " https://sourceforge.net/projects/simpybigtwo/ 扑克中的“大老二”  https://www.wikihow.com/Play-Big-Two\n",
    " \n",
    " https://www.datacamp.com/community/tutorials/python-probability-tutorial Analyzing Poker Hands with Python\n",
    " \n",
    " http://openbookproject.net/books/bpp4awd/ch08.html Card objects as an example.\n",
    " \n",
    " https://blog.csdn.net/wzebinbin/article/details/78299677 AlphaGo Zero论文中文版:\n",
    " \n",
    " https://cloud.tencent.com/developer/article/1051220  强化学习系统\n",
    " \n",
    " https://cloud.tencent.com/developer/article/1051227 强化学习系统\n",
    " \n",
    " http://tigerneil.github.io/2016/05/30/nsfp/ 不完全信息博弈中自我对弈的深度强化学习技术 \n",
    " \n",
    " https://blog.csdn.net/Luke__/article/details/53000497 扑克牌游戏出牌规则\n",
    " \n",
    " https://baike.baidu.com/item/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/5500990?fr=aladdin 贝尔曼方程 也被称作动态规划方程\n",
    " \n",
    " https://baike.baidu.com/item/%E7%BA%B3%E4%BB%80%E5%9D%87%E8%A1%A1/534868?fr=aladdin Nash平衡\n",
    " \n",
    " https://cloud.tencent.com/developer/article/1150412 Neural Fictitious Self Play——从博弈论到深度强化学习\n",
    " \n",
    " https://blog.csdn.net/Mbx8X9u/article/details/80780459 强化学习学习资料\n",
    " \n",
    " https://github.com/ShangtongZhang/reinforcement-learning-an-introduction 强化学习课程代码 \n",
    " \n",
    " https://www.zhihu.com/question/49230922?sort=created  强化学习资源\n",
    " \n",
    " https://jizhi.im/blog/post/rl_intro 极简增强学习新手教程\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
