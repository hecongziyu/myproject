{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "goolge ocr mathematics formula\n",
    "2、https://blog.csdn.net/Jeremy_lf/article/details/102728778  https://blog.csdn.net/Jeremy_lf/article/details/102869629 数学公式识别论文一\n",
    "3、https://github.com/luopeixiang/im2latex ！！！\n",
    "4、https://guillaumegenthial.github.io/image-to-latex.html ！！！\n",
    "5、https://github.com/harvardnlp/im2markup\n",
    "5、https://www.ocr.org.uk/Images/73472-datasheet-examination-formulae-and-statistical-tables.pdf ！！\n",
    "6、http://lstm.seas.harvard.edu/latex/ Image-to-Markup Generation with Coarse-to-Fine Attention\n",
    "7、https://github.com/LinXueyuanStdio/LaTeX_OCR ！！！\n",
    "8、https://blog.csdn.net/wxplol/article/details/99941160 ！！！！  其中包括位置信息的解释\n",
    "9、https://www.ocr.org.uk/Images/73472-datasheet-examination-formulae-and-statistical-tables.pdf \n",
    "10、https://arxiv.org/ftp/arxiv/papers/1908/1908.11415.pdf Translating Math Formula Images to LaTeX Sequences Using Deep Neural Networks with Sequence-level Training \n",
    "11、https://scholarworks.sjsu.edu/cgi/viewcontent.cgi?referer=https://www.google.com/&httpsredir=1&article=1599&context=etd_projects ！\n",
    "12、https://towardsdatascience.com/deep-learning-for-symbolic-mathematics-5830b22063d0\n",
    "13、http://lstm.seas.harvard.edu/latex/\n",
    "14、https://arxiv.org/ftp/arxiv/papers/2003/2003.00817.pdf 手写体数学公式识别\n",
    "15、https://blog.csdn.net/AckClinkz/article/details/78279074  BLEU1（bilingual evaluation understudy）最早由IBM提出，用来评价翻译质量\n",
    "16、https://blog.csdn.net/lnformat/article/details/88639607\n",
    "17、https://zhidao.baidu.com/question/1990959368206778587.html 数学中的Sin和Cos是什么意思 （在一个平面直角坐标系中，以原点为圆心，1 为半径画一个圆，这个圆交 x 轴于 A 点。以 O 为旋转中心，将 A 点逆时针旋转一定的角度α至 B 点，设此时 B 点的坐标是(x,y)，那么此时 y 的值就叫做α的正弦，记作 sinα；此时 x 的值就叫做α的余弦，）\n",
    "18、https://github.com/antonvladyka/neuralnetworksanddeeplearning.com.pdf\n",
    "19、https://github.com/harvardnlp/im2markup \n",
    "20、https://github.com/luopeixiang ！！！！！\n",
    "21、https://www.zhihu.com/question/347678607/answer/834903728 如何理解Transformer论文中的positional encoding，和三角函数有什么关系？\n",
    "22、https://blog.csdn.net/qq_16234613/article/details/83012046 NLP 自然语言处理 集束搜索beam search和贪心搜索greedy search\n",
    "23、https://github.com/jtyoui/Jtyoui/tree/master/jtyoui/statistics/maths \n",
    "24、https://github.com/rsmith-nl/texcalc 计算latex 结果\n",
    "25、https://github.com/roniemartinez/latex2mathml MathML H5数学表达式\n",
    "26、https://www.cnblogs.com/3daytears/p/9236175.html 生成latex格式公式\n",
    "27、https://pylatexenc.readthedocs.io/en/latest/ convert latex to regular mathematical\n",
    "28、https://www.cnblogs.com/3daytears/p/9236175.html ！！！\n",
    "29、https://pylatexenc.readthedocs.io/en/latest/latexwalker/ Simple Parser for LaTeX Code\n",
    "30、https://github.com/augustt198/latex2sympy\n",
    "31、https://github.com/jungomi/math-formula-recognition Multi-Scale Attention with Dense Encoder for Handwritten Mathematical Expression Recognition.\n",
    "32、https://blog.csdn.net/cj151525/article/details/95756847 python sympy\n",
    "convert LaTeX into a regular mathematical expression ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:14:41.761467Z",
     "start_time": "2020-04-16T13:14:41.042652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\sqrt{\\frac{2}{2}+100}$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$\\sqrt{\\frac{2}{2}+100}$$\n",
      "ss -> $$\\sqrt{\\frac{2}{2}+100}$$\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.707106781186548$"
      ],
      "text/plain": [
       "0.707106781186548"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Latex\n",
    "from pytexit import py2tex\n",
    "ss = py2tex(r'sqrt(2/2 + 100)')\n",
    "print('ss ->', ss)\n",
    "Latex(ss)\n",
    "# 下载 anltr https://www.cnblogs.com/solvit/p/10097234.html,\n",
    "# 执行 antlr4 PS.g4 -o gen 生成解释代码  https://github.com/augustt198/latex2sympy\n",
    "\n",
    "import sympy\n",
    "sympy.simplify('sqrt(2/2-0.5)')\n",
    "#注意 sympy开根号不显示无理数，只会sqrt方式显示。比如8–√=22–√8 ​=22​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T08:45:05.422508Z",
     "start_time": "2020-04-16T08:45:05.351547Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "https://github.com/luopeixiang/im2latex\n",
    "https://blog.csdn.net/SHU15121856/article/details/104448734 nn.LSTM和nn.LSTMCell的使用\n",
    "\n",
    "'''\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from torch.distributions.uniform import Uniform\n",
    "\n",
    "def add_positional_features(tensor: torch.Tensor,\n",
    "                            min_timescale: float = 1.0,\n",
    "                            max_timescale: float = 1.0e4):\n",
    "    \"\"\"\n",
    "    Implements the frequency-based positional encoding described\n",
    "    in `Attention is all you Need\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor : ``torch.Tensor``\n",
    "        a Tensor with shape (batch_size, timesteps, hidden_dim).\n",
    "    min_timescale : ``float``, optional (default = 1.0)\n",
    "        The largest timescale to use.\n",
    "    Returns\n",
    "    -------\n",
    "    The input tensor augmented with the sinusoidal frequencies.\n",
    "    \"\"\"\n",
    "    _, timesteps, hidden_dim = tensor.size()\n",
    "    timestep_range = get_range_vector(timesteps, tensor.device).data.float()\n",
    "    # We're generating both cos and sin frequencies,\n",
    "    # so half for each.\n",
    "    num_timescales = hidden_dim // 2\n",
    "    timescale_range = get_range_vector(num_timescales, tensor.device).data.float()\n",
    "\n",
    "    log_timescale_increments = math.log(float(max_timescale) / float(min_timescale)) / float(num_timescales - 1)\n",
    "    inverse_timescales = min_timescale * \\\n",
    "        torch.exp(timescale_range * -log_timescale_increments)\n",
    "\n",
    "    # Broadcasted multiplication - shape (timesteps, num_timescales)\n",
    "    scaled_time = timestep_range.unsqueeze(1) * inverse_timescales.unsqueeze(0)\n",
    "    # shape (timesteps, 2 * num_timescales)\n",
    "    sinusoids = torch.randn(scaled_time.size(0), 2*scaled_time.size(1), device=tensor.device)\n",
    "    sinusoids[:, ::2] = torch.sin(scaled_time)\n",
    "    sinusoids[:, 1::2] = torch.cos(scaled_time)\n",
    "    if hidden_dim % 2 != 0:\n",
    "        # if the number of dimensions is odd, the cos and sin\n",
    "        # timescales had size (hidden_dim - 1) / 2, so we need\n",
    "        # to add a row of zeros to make up the difference.\n",
    "        sinusoids = torch.cat([sinusoids, sinusoids.new_zeros(timesteps, 1)], 1)\n",
    "    return tensor + sinusoids.unsqueeze(0)\n",
    "\n",
    "def get_range_vector(size: int, device) -> torch.Tensor:\n",
    "    return torch.arange(0, size, dtype=torch.long, device=device)\n",
    "\n",
    "INIT = 1e-2\n",
    "\n",
    "class Im2LatexModel(nn.Module):\n",
    "    def __init__(self, out_size, emb_size, dec_rnn_h,\n",
    "                 enc_out_dim=512,  n_layer=1,\n",
    "                 add_pos_feat=False, dropout=0.):\n",
    "        super(Im2LatexModel, self).__init__()\n",
    "\n",
    "        self.cnn_encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 1),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 1),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 1), (2, 1), 0),\n",
    "\n",
    "            nn.Conv2d(256, enc_out_dim, 3, 1, 0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.rnn_decoder = nn.LSTMCell(dec_rnn_h+emb_size, dec_rnn_h)\n",
    "        self.embedding = nn.Embedding(out_size, emb_size)\n",
    "\n",
    "        self.init_wh = nn.Linear(enc_out_dim, dec_rnn_h)\n",
    "        self.init_wc = nn.Linear(enc_out_dim, dec_rnn_h)\n",
    "        self.init_wo = nn.Linear(enc_out_dim, dec_rnn_h)\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.beta = nn.Parameter(torch.Tensor(enc_out_dim))\n",
    "        init.uniform_(self.beta, -INIT, INIT)\n",
    "        self.W_1 = nn.Linear(enc_out_dim, enc_out_dim, bias=False)\n",
    "        self.W_2 = nn.Linear(dec_rnn_h, enc_out_dim, bias=False)\n",
    "\n",
    "        self.W_3 = nn.Linear(dec_rnn_h+enc_out_dim, dec_rnn_h, bias=False)\n",
    "        self.W_out = nn.Linear(dec_rnn_h, out_size, bias=False)\n",
    "\n",
    "        self.add_pos_feat = add_pos_feat\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.uniform = Uniform(0, 1)\n",
    "\n",
    "    def forward(self, imgs, formulas, epsilon=1.):\n",
    "        \"\"\"args:\n",
    "        imgs: [B, C, H, W]\n",
    "        formulas: [B, MAX_LEN]\n",
    "        epsilon: probability of the current time step to  use the true previous token\n",
    "        return:\n",
    "        logits: [B, MAX_LEN, VOCAB_SIZE]\n",
    "        \"\"\"\n",
    "        # encoding\n",
    "        encoded_imgs = self.encode(imgs)  # [B, H*W, 512]\n",
    "        # init decoder's states  ？？？？？？？？？？\n",
    "        dec_states, o_t = self.init_decoder(encoded_imgs)\n",
    "        max_len = formulas.size(1)\n",
    "        logits = []\n",
    "        for t in range(max_len):\n",
    "            tgt = formulas[:, t:t+1]\n",
    "            # schedule sampling\n",
    "            if logits and self.uniform.sample().item() > epsilon:\n",
    "                tgt = torch.argmax(torch.log(logits[-1]), dim=1, keepdim=True)\n",
    "            # ont step decoding\n",
    "            dec_states, O_t, logit = self.step_decoding(dec_states, o_t, encoded_imgs, tgt)\n",
    "            logits.append(logit)\n",
    "        logits = torch.stack(logits, dim=1)  # [B, MAX_LEN, out_size]\n",
    "        return logits\n",
    "\n",
    "    def encode(self, imgs):\n",
    "        encoded_imgs = self.cnn_encoder(imgs)  # [B, 512, H', W']\n",
    "        encoded_imgs = encoded_imgs.permute(0, 2, 3, 1)  # [B, H', W', 512]\n",
    "        B, H, W, _ = encoded_imgs.shape\n",
    "        encoded_imgs = encoded_imgs.contiguous().view(B, H*W, -1)\n",
    "        if self.add_pos_feat:\n",
    "            encoded_imgs = add_positional_features(encoded_imgs)\n",
    "        return encoded_imgs\n",
    "\n",
    "    \n",
    "    def step_decoding(self, dec_states, o_t, enc_out, tgt):\n",
    "        \"\"\"\n",
    "            Runing one step decoding\n",
    "            dec_states : (h_t, c_t)\n",
    "            o_t: atten scores\n",
    "            enc_out: pre logits\n",
    "            tgt: pre true target\n",
    "        \"\"\"\n",
    "\n",
    "        prev_y = self.embedding(tgt).squeeze(1)  # [B, emb_size]\n",
    "        inp = torch.cat([prev_y, o_t], dim=1)  # [B, emb_size+dec_rnn_h]\n",
    "        h_t, c_t = self.rnn_decoder(inp, dec_states)  # h_t:[B, dec_rnn_h]\n",
    "        h_t = self.dropout(h_t)\n",
    "        c_t = self.dropout(c_t)\n",
    "\n",
    "        # context_t : [B, C]\n",
    "        context_t, attn_scores = self._get_attn(enc_out, h_t)\n",
    "\n",
    "        # [B, dec_rnn_h]\n",
    "        o_t = self.W_3(torch.cat([h_t, context_t], dim=1)).tanh()\n",
    "        o_t = self.dropout(o_t)\n",
    "\n",
    "        # calculate logit\n",
    "        logit = F.softmax(self.W_out(o_t), dim=1)  # [B, out_size]\n",
    "\n",
    "        return (h_t, c_t), o_t, logit\n",
    "\n",
    "    def _get_attn(self, enc_out, h_t):\n",
    "        \"\"\"Attention mechanism\n",
    "        args:\n",
    "            enc_out: row encoder's output [B, L=H*W, C]\n",
    "            h_t: the current time step hidden state [B, dec_rnn_h]\n",
    "        return:\n",
    "            context: this time step context [B, C]\n",
    "            attn_scores: Attention scores\n",
    "        \"\"\"\n",
    "        # cal alpha\n",
    "        alpha = torch.tanh(self.W_1(enc_out)+self.W_2(h_t).unsqueeze(1))\n",
    "        alpha = torch.sum(self.beta*alpha, dim=-1)  # [B, L]\n",
    "        alpha = F.softmax(alpha, dim=-1)  # [B, L]\n",
    "\n",
    "        # cal context: [B, C]\n",
    "        context = torch.bmm(alpha.unsqueeze(1), enc_out)\n",
    "        context = context.squeeze(1)\n",
    "        return context, alpha\n",
    "\n",
    "    def init_decoder(self, enc_out):\n",
    "        \"\"\"args:\n",
    "            enc_out: the output of row encoder [B, H*W, C]\n",
    "          return:\n",
    "            h_0, c_0:  h_0 and c_0's shape: [B, dec_rnn_h]\n",
    "            init_O : the average of enc_out  [B, dec_rnn_h]\n",
    "            for decoder\n",
    "        \"\"\"\n",
    "        mean_enc_out = enc_out.mean(dim=1)\n",
    "        h = self._init_h(mean_enc_out)\n",
    "        c = self._init_c(mean_enc_out)\n",
    "        init_o = self._init_o(mean_enc_out)\n",
    "        return (h, c), init_o\n",
    "\n",
    "    def _init_h(self, mean_enc_out):\n",
    "        return torch.tanh(self.init_wh(mean_enc_out))\n",
    "\n",
    "    def _init_c(self, mean_enc_out):\n",
    "        return torch.tanh(self.init_wc(mean_enc_out))\n",
    "\n",
    "    def _init_o(self, mean_enc_out):\n",
    "        return torch.tanh(self.init_wo(mean_enc_out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T07:57:37.195300Z",
     "start_time": "2020-04-16T07:57:37.153323Z"
    },
    "code_folding": [
     104
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from lib.im2latex.utils import cal_loss, cal_epsilon\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, optimizer, model, lr_scheduler,\n",
    "                 train_loader, val_loader, args,\n",
    "                 use_cuda=False, init_epoch=1, last_epoch=15):\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.args = args\n",
    "        self.step = 0\n",
    "        self.epoch = init_epoch\n",
    "        self.total_step = (init_epoch-1)*len(train_loader)\n",
    "        self.last_epoch = last_epoch\n",
    "        self.best_val_loss = 1e18\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    def train(self):\n",
    "        mes = \"Epoch {}, step:{}/{} {:.2f}%, Loss:{:.4f}, Perplexity:{:.4f}\"\n",
    "        while self.epoch <= self.last_epoch:\n",
    "            self.model.train()\n",
    "            losses = 0.0\n",
    "            #  tgt4training 字符串开始标记<s>, tgt4cal_loss 字符串结束标记</s>    \n",
    "            for imgs, tgt4training, tgt4cal_loss in self.train_loader:\n",
    "                step_loss = self.train_step(imgs, tgt4training, tgt4cal_loss)\n",
    "                losses += step_loss\n",
    "\n",
    "                # log message\n",
    "                if self.step % self.args.print_freq == 0:\n",
    "                    avg_loss = losses / self.args.print_freq\n",
    "                    print(mes.format(\n",
    "                        self.epoch, self.step, len(self.train_loader),\n",
    "                        100 * self.step / len(self.train_loader),\n",
    "                        avg_loss,\n",
    "                        2**avg_loss\n",
    "                    ))\n",
    "                    losses = 0.0\n",
    "\n",
    "            # one epoch Finished, calcute val loss\n",
    "            val_loss = self.validate()\n",
    "            self.lr_scheduler.step(val_loss)\n",
    "\n",
    "            self.save_model('ckpt-{}-{:.4f}'.format(self.epoch, val_loss))\n",
    "            self.epoch += 1\n",
    "            self.step = 0\n",
    "\n",
    "    def train_step(self, imgs, tgt4training, tgt4cal_loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        imgs = imgs.to(self.device)\n",
    "        tgt4training = tgt4training.to(self.device)\n",
    "        tgt4cal_loss = tgt4cal_loss.to(self.device)\n",
    "\n",
    "        '''\n",
    "        Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\n",
    "        See details in https://arxiv.org/pdf/1506.03099.pdf\n",
    "        '''\n",
    "        epsilon = cal_epsilon(self.args.decay_k, self.total_step, self.args.sample_method)\n",
    "\n",
    "        '''\n",
    "        https://www.zhihu.com/question/60751553 如何理解深度学习源码里经常出现的logits？\n",
    "        logits: 一个事件发生与该事件不发生的比值的对数（统计学习方法-李航 p78）。假设一个事件发生的概率为 p，那么该事件的 logits 为 logit(p) = log(p/1-p) .\n",
    "        '''\n",
    "        logits = self.model(imgs, tgt4training, epsilon)\n",
    "\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = cal_loss(logits, tgt4cal_loss)\n",
    "        self.step += 1\n",
    "        self.total_step += 1\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(self.model.parameters(), self.args.clip)\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        val_total_loss = 0.0\n",
    "        mes = \"Epoch {}, validation average loss:{:.4f}, Perplexity:{:.4f}\"\n",
    "        with torch.no_grad():\n",
    "            for imgs, tgt4training, tgt4cal_loss in self.val_loader:\n",
    "                imgs = imgs.to(self.device)\n",
    "                tgt4training = tgt4training.to(self.device)\n",
    "                tgt4cal_loss = tgt4cal_loss.to(self.device)\n",
    "\n",
    "                epsilon = cal_epsilon(\n",
    "                    self.args.decay_k, self.total_step, self.args.sample_method)\n",
    "                logits = self.model(imgs, tgt4training, epsilon)\n",
    "                loss = cal_loss(logits, tgt4cal_loss)\n",
    "                val_total_loss += loss\n",
    "            avg_loss = val_total_loss / len(self.val_loader)\n",
    "            print(mes.format(\n",
    "                self.epoch, avg_loss, 2**avg_loss\n",
    "            ))\n",
    "        if avg_loss < self.best_val_loss:\n",
    "            self.best_val_loss = avg_loss\n",
    "            self.save_model('best_ckpt')\n",
    "        return avg_loss\n",
    "\n",
    "    def save_model(self, model_name):\n",
    "        if not os.path.isdir(self.args.save_dir):\n",
    "            os.makedirs(self.args.save_dir)\n",
    "        save_path = join(self.args.save_dir, model_name+'.pt')\n",
    "        print(\"Saving checkpoint to {}\".format(save_path))\n",
    "\n",
    "        # torch.save(self.model, model_path)\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'lr_sche': self.lr_scheduler.state_dict(),\n",
    "            'epoch': self.epoch,\n",
    "            'args': self.args\n",
    "        }, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T09:04:36.586252Z",
     "start_time": "2020-04-16T09:04:36.529283Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from lib.im2latex.utils import collate_fn, get_checkpoint\n",
    "from lib.im2latex.data import Im2LatexDataset\n",
    "from lib.im2latex.build_vocab import Vocab, load_vocab\n",
    "def init_loader():\n",
    "    # get args\n",
    "    parser = argparse.ArgumentParser(description=\"Im2Latex Training Program\")\n",
    "    # parser.add_argument('--path', required=True, help='root of the model')\n",
    "    # model args\n",
    "    parser.add_argument(\"--emb_dim\", type=int, default=80, help=\"Embedding size\")\n",
    "    parser.add_argument(\"--dec_rnn_h\", type=int, default=512, help=\"The hidden state of the decoder RNN\")\n",
    "    parser.add_argument(\"--data_path\", type=str, default=\"D:\\\\PROJECT_TW\\\\git\\\\data\\\\im2latex\", help=\"The dataset's dir\")\n",
    "    parser.add_argument(\"--add_position_features\", action='store_true', default=True, help=\"Use position embeddings or not\")\n",
    "    # training args\n",
    "    parser.add_argument(\"--max_len\", type=int, default=150, help=\"Max size of formula\")\n",
    "    parser.add_argument(\"--dropout\", type=float,default=0., help=\"Dropout probility\")\n",
    "    parser.add_argument(\"--cuda\", action='store_true',default=True, help=\"Use cuda or not\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--epoches\", type=int, default=15)\n",
    "    parser.add_argument(\"--lr\", type=float, default=3e-4,help=\"Learning Rate\")\n",
    "    parser.add_argument(\"--min_lr\", type=float, default=3e-5, help=\"Learning Rate\")\n",
    "    parser.add_argument(\"--sample_method\", type=str, default=\"teacher_forcing\", choices=('teacher_forcing', 'exp', 'inv_sigmoid'), help=\"The method to schedule sampling\")\n",
    "    parser.add_argument(\"--decay_k\", type=float, default=1.,\n",
    "                        help=\"Base of Exponential decay for Schedule Sampling. \"\n",
    "                        \"When sample method is Exponential deca;\"\n",
    "                        \"Or a constant in Inverse sigmoid decay Equation. \"\n",
    "                        \"See details in https://arxiv.org/pdf/1506.03099.pdf\")\n",
    "    parser.add_argument(\"--lr_decay\", type=float, default=0.5, help=\"Learning Rate Decay Rate\")\n",
    "    parser.add_argument(\"--lr_patience\", type=int, default=3,  help=\"Learning Rate Decay Patience\")\n",
    "    parser.add_argument(\"--clip\", type=float, default=2.0, help=\"The max gradient norm\")\n",
    "    parser.add_argument(\"--save_dir\", type=str, default=\"D:\\\\PROJECT_TW\\\\git\\\\data\\\\im2latex\\\\ckpts\", help=\"The dir to save checkpoints\")\n",
    "    parser.add_argument(\"--print_freq\", type=int, default=100, help=\"The frequency to print message\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=2020, help=\"The random seed for reproducing \")\n",
    "    parser.add_argument(\"--from_check_point\", action='store_true', default=False, help=\"Training from checkpoint or not\")\n",
    "    #  注意在 jupyter notebook 需带args=[] 这个参数\n",
    "    args = parser.parse_args(args=[])\n",
    "    max_epoch = args.epoches\n",
    "    from_check_point = args.from_check_point\n",
    "    if from_check_point:\n",
    "        checkpoint_path = get_checkpoint(args.save_dir)\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        args = checkpoint['args']\n",
    "    print(\"Training args:\", args)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    # Building vocab\n",
    "    print(\"Load vocab...\")\n",
    "    vocab = load_vocab(args.data_path)\n",
    "#     print('vocab -->', vocab.sign2id)\n",
    "    use_cuda = True if args.cuda and torch.cuda.is_available() else False\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    # data loader\n",
    "    print(\"Construct data loader...\")\n",
    "    train_loader = None\n",
    "#     train_loader = DataLoader(\n",
    "#         Im2LatexDataset(args.data_path, 'train', args.max_len),\n",
    "#         batch_size=args.batch_size,\n",
    "#         collate_fn=partial(collate_fn, vocab.sign2id),\n",
    "#         pin_memory=True if use_cuda else False,\n",
    "#         num_workers=1)\n",
    "    val_loader = DataLoader(\n",
    "        Im2LatexDataset(args.data_path, 'validate', args.max_len),\n",
    "        batch_size=args.batch_size,\n",
    "        collate_fn=partial(collate_fn, vocab.sign2id),\n",
    "        pin_memory=True if use_cuda else False,\n",
    "        num_workers=1)\n",
    "    print(\"Construct data loader over\")\n",
    "    return train_loader, val_loader,vocab, args\n",
    "\n",
    "def train(train_loader,val_loader, vocab, args):\n",
    "    use_cuda = True if args.cuda and torch.cuda.is_available() else False\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")    \n",
    "    # construct model\n",
    "    print(\"Construct model\")\n",
    "    vocab_size = len(vocab)\n",
    "    model = Im2LatexModel(\n",
    "        vocab_size, args.emb_dim, args.dec_rnn_h,\n",
    "        add_pos_feat=args.add_position_features,\n",
    "        dropout=args.dropout\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    print(\"Model Settings:\")\n",
    "    print(model)  \n",
    "    # construct optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    lr_scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        \"min\",\n",
    "        factor=args.lr_decay,\n",
    "        patience=args.lr_patience,\n",
    "        verbose=True,\n",
    "        min_lr=args.min_lr)    \n",
    "    \n",
    "    if from_check_point:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_sche'])\n",
    "        # init trainer from checkpoint\n",
    "        trainer = Trainer(optimizer, model, lr_scheduler,\n",
    "                          train_loader, val_loader, args,\n",
    "                          use_cuda=use_cuda,\n",
    "                          init_epoch=epoch, last_epoch=max_epoch)\n",
    "    else:\n",
    "        trainer = Trainer(optimizer, model, lr_scheduler,\n",
    "                          train_loader, val_loader, args,\n",
    "                          use_cuda=use_cuda,\n",
    "                          init_epoch=1, last_epoch=args.epoches)\n",
    "    # begin training\n",
    "    trainer.train()    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T09:01:36.093941Z",
     "start_time": "2020-04-16T09:01:22.165917Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training args: Namespace(add_position_features=True, batch_size=32, clip=2.0, cuda=True, data_path='D:\\\\PROJECT_TW\\\\git\\\\data\\\\im2latex', dec_rnn_h=512, decay_k=1.0, dropout=0.0, emb_dim=80, epoches=15, from_check_point=False, lr=0.0003, lr_decay=0.5, lr_patience=3, max_len=150, min_lr=3e-05, print_freq=100, sample_method='teacher_forcing', save_dir='D:\\\\PROJECT_TW\\\\git\\\\data\\\\im2latex\\\\ckpts', seed=2020)\n",
      "Load vocab...\n",
      "Load vocab including 394 words!\n",
      "Construct data loader...\n",
      "Construct data loader over\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "train_loader, val_loader,vocab, args =  init_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T09:02:47.112932Z",
     "start_time": "2020-04-16T09:02:47.019987Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct model\n",
      "Model Settings:\n",
      "Im2LatexModel(\n",
      "  (cnn_encoder): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (12): ReLU()\n",
      "  )\n",
      "  (rnn_decoder): LSTMCell(592, 512)\n",
      "  (embedding): Embedding(394, 80)\n",
      "  (init_wh): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (init_wc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (init_wo): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (W_1): Linear(in_features=512, out_features=512, bias=False)\n",
      "  (W_2): Linear(in_features=512, out_features=512, bias=False)\n",
      "  (W_3): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (W_out): Linear(in_features=512, out_features=394, bias=False)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "train(train_loader, val_loader,vocab, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T08:59:46.772949Z",
     "start_time": "2020-04-16T08:59:46.604065Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
