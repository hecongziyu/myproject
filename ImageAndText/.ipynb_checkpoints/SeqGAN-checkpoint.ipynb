{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本说明 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    https://cloud.tencent.com/developer/article/1162834\n",
    "    https://www.zhihu.com/question/52602529/answer/155743699\n",
    "    https://github.com/ZiJianZhao/SeqGAN-PyTorch\n",
    "    https://github.com/ChenChengKuan/SeqGAN_tensorflow\n",
    "    https://github.com/suragnair/seqGAN\n",
    "    \n",
    "    https://arxiv.org/pdf/1609.05473.pdf\n",
    "    \n",
    "    https://baike.baidu.com/item/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/3350286?fr=aladdin  MLE 极大似然估计\n",
    "    https://blog.csdn.net/lanchunhui/article/details/51248184 softmax 及 logsoftmax\n",
    "    \n",
    "    https://blog.csdn.net/bobobe/article/details/81297064  scheduled sampling （计划采样）\n",
    "    http://papers.nips.cc/paper/5956-scheduled-sampling-for-sequence-prediction-with-recurrent-neural-networks.pdf  计划采样\n",
    "    https://blog.csdn.net/dukuku5038/article/details/84060969  Scheduled Sampling\n",
    "    https://stackoverflow.com/questions/43795423/scheduled-sampling-in-tensorflow \n",
    "    https://github.com/TobiasLee/SeqGAN_Poem 诗歌\n",
    "    \n",
    "    SeqGAN significantly outperforms the maximum likelihood methods, scheduled sampling and PG-BLEU\n",
    "    https://www.jianshu.com/p/15c22fadcba5 机器翻译质量评测算法-BLEU\n",
    "    https://cloud.tencent.com/developer/article/1042161 浅谈用Python计算文本BLEU分数\n",
    "    https://blog.csdn.net/dlphay/article/details/78200396 Policy Gradient简述\n",
    "    https://blog.csdn.net/suai9292/article/details/79910525 Policy Gradient理解\n",
    "    https://blog.csdn.net/u013084616/article/details/79023354  Highway Network 在判断器中使用了highway方式，解决训练困难的问题 。。。\n",
    "    \n",
    "    https://www.leiphone.com/news/201810/cTCGyCN8w6pfRm0C.html 通过多对抗训练，从图像生成诗歌 \n",
    "    https://www.jianshu.com/p/e1b87286bfae  SeqGAN解读\n",
    "    \n",
    "    \n",
    "    \n",
    "    http://www.eeworld.com.cn/mp/QbitAI/a53664.jspx 韩国小哥哥用Pytorch实现谷歌最强NLP预训练模型BERT | 代码\n",
    "    \n",
    "    https://blog.csdn.net/zhl493722771/article/details/82781914 令人拍案叫绝的WGAN\n",
    "    \n",
    "    https://www.colabug.com/2639033.html 对抗思想与强化学习的碰撞-SeqGAN模型原理和代码解析\n",
    "    \n",
    "    https://blog.csdn.net/Irving_zhang/article/details/79088143  实现基于seq2seq的聊天机器人\n",
    "    \n",
    "    https://www.leiphone.com/news/201709/QRJPQr3jCOtY7ncQ.html 如何让对抗网络GAN生成更高质量的文本？\n",
    "    \n",
    "    https://blog.csdn.net/Young_Gy/article/details/76474939  构建聊天机器人：检索、seq2seq、RL、SeqGAN\n",
    "    \n",
    "    https://blog.csdn.net/yinruiyang94/article/details/77675586 SeqGAN——对抗思想与增强学习的碰撞\n",
    "    \n",
    "    https://blog.csdn.net/qunnie_yi/article/details/80129851 只知道GAN你就OUT了——VAE背后的哲学思想及数学原理\n",
    "    \n",
    "    https://blog.csdn.net/GitChat/article/details/79081190 手把手教你写一个中文聊天机器人\n",
    "    \n",
    "    https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/79184714 一文读懂智能对话系统\n",
    "    \n",
    "    https://blog.csdn.net/taoyafan/article/details/81229466#1%20%E4%BB%80%E4%B9%88%E6%98%AF%20Condition%20GAN  Condition GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 强化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " https://www.cnblogs.com/steven-yang/p/6624253.html 强化学习读书笔记 - 13 - 策略梯度方法(Policy Gradient Methods)\n",
    " https://blog.csdn.net/aliceyangxi1987/article/details/73327378 一文了解强化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     32,
     62,
     82
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data ...\n",
      "Pretrain with MLE ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project_tw\\anly\\venv\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0] Model Loss: 49.825607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project_tw\\anly\\venv\\lib\\site-packages\\ipykernel_launcher.py:96: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0] True Loss: 439.707668\n",
      "Epoch [1] Model Loss: 49.359363\n",
      "Epoch [1] True Loss: 486.926280\n",
      "Epoch [2] Model Loss: 48.763727\n",
      "Epoch [2] True Loss: 410.003515\n",
      "Epoch [3] Model Loss: 47.835021\n",
      "Epoch [3] True Loss: 405.153796\n",
      "Epoch [4] Model Loss: 46.210295\n",
      "Epoch [4] True Loss: 409.418591\n",
      "Epoch [5] Model Loss: 42.546495\n",
      "Epoch [5] True Loss: 377.222284\n",
      "Epoch [6] Model Loss: 36.777756\n",
      "Epoch [6] True Loss: 249.282105\n",
      "Epoch [7] Model Loss: 33.624580\n",
      "Epoch [7] True Loss: 228.912664\n",
      "Epoch [8] Model Loss: 32.428944\n",
      "Epoch [8] True Loss: 220.253196\n",
      "Epoch [9] Model Loss: 31.953266\n",
      "Epoch [9] True Loss: 195.111094\n",
      "Epoch [10] Model Loss: 31.642862\n",
      "Epoch [10] True Loss: 210.281344\n",
      "Epoch [11] Model Loss: 31.336355\n",
      "Epoch [11] True Loss: 218.198054\n",
      "Epoch [12] Model Loss: 31.179035\n",
      "Epoch [12] True Loss: 201.409528\n",
      "Epoch [13] Model Loss: 31.048143\n",
      "Epoch [13] True Loss: 206.758226\n",
      "Epoch [14] Model Loss: 30.941812\n",
      "Epoch [14] True Loss: 230.251738\n",
      "Epoch [15] Model Loss: 30.844661\n",
      "Epoch [15] True Loss: 196.807498\n",
      "Epoch [16] Model Loss: 30.746876\n",
      "Epoch [16] True Loss: 217.830565\n",
      "Epoch [17] Model Loss: 30.669189\n",
      "Epoch [17] True Loss: 202.417577\n",
      "Epoch [18] Model Loss: 30.589751\n",
      "Epoch [18] True Loss: 196.511171\n",
      "Epoch [19] Model Loss: 30.492608\n",
      "Epoch [19] True Loss: 209.378053\n",
      "Epoch [20] Model Loss: 30.432588\n",
      "Epoch [20] True Loss: 206.654733\n",
      "Epoch [21] Model Loss: 30.342518\n",
      "Epoch [21] True Loss: 194.652314\n",
      "Epoch [22] Model Loss: 30.265442\n",
      "Epoch [22] True Loss: 204.345815\n",
      "Epoch [23] Model Loss: 30.178205\n",
      "Epoch [23] True Loss: 216.435821\n",
      "Epoch [24] Model Loss: 30.102400\n",
      "Epoch [24] True Loss: 205.168689\n",
      "Epoch [25] Model Loss: 30.020279\n",
      "Epoch [25] True Loss: 189.303483\n",
      "Epoch [26] Model Loss: 29.938560\n",
      "Epoch [26] True Loss: 215.853396\n",
      "Epoch [27] Model Loss: 29.857569\n",
      "Epoch [27] True Loss: 200.734161\n",
      "Epoch [28] Model Loss: 29.757436\n",
      "Epoch [28] True Loss: 189.542300\n",
      "Epoch [29] Model Loss: 29.672378\n",
      "Epoch [29] True Loss: 181.294682\n",
      "Epoch [30] Model Loss: 29.581963\n",
      "Epoch [30] True Loss: 197.178724\n",
      "Epoch [31] Model Loss: 29.484013\n",
      "Epoch [31] True Loss: 205.391671\n",
      "Epoch [32] Model Loss: 29.380201\n",
      "Epoch [32] True Loss: 185.563610\n",
      "Epoch [33] Model Loss: 29.292479\n",
      "Epoch [33] True Loss: 187.488130\n",
      "Epoch [34] Model Loss: 29.190030\n",
      "Epoch [34] True Loss: 177.237935\n",
      "Epoch [35] Model Loss: 29.095701\n",
      "Epoch [35] True Loss: 182.223083\n",
      "Epoch [36] Model Loss: 28.992462\n",
      "Epoch [36] True Loss: 183.951053\n",
      "Epoch [37] Model Loss: 28.893191\n",
      "Epoch [37] True Loss: 193.720437\n",
      "Epoch [38] Model Loss: 28.783889\n",
      "Epoch [38] True Loss: 184.862290\n",
      "Epoch [39] Model Loss: 28.672724\n",
      "Epoch [39] True Loss: 178.448653\n",
      "Epoch [40] Model Loss: 28.560681\n",
      "Epoch [40] True Loss: 191.728835\n",
      "Epoch [41] Model Loss: 28.421714\n",
      "Epoch [41] True Loss: 183.447122\n",
      "Epoch [42] Model Loss: 28.277617\n",
      "Epoch [42] True Loss: 169.932897\n",
      "Epoch [43] Model Loss: 28.111173\n",
      "Epoch [43] True Loss: 181.131456\n",
      "Epoch [44] Model Loss: 27.989570\n",
      "Epoch [44] True Loss: 160.319233\n",
      "Epoch [45] Model Loss: 27.844849\n",
      "Epoch [45] True Loss: 173.452836\n",
      "Epoch [46] Model Loss: 27.698816\n",
      "Epoch [46] True Loss: 188.834497\n",
      "Epoch [47] Model Loss: 27.587119\n",
      "Epoch [47] True Loss: 181.869347\n",
      "Epoch [48] Model Loss: 27.445860\n",
      "Epoch [48] True Loss: 165.325122\n",
      "Epoch [49] Model Loss: 27.334277\n",
      "Epoch [49] True Loss: 177.795078\n",
      "Epoch [50] Model Loss: 27.226250\n",
      "Epoch [50] True Loss: 154.370236\n",
      "Epoch [51] Model Loss: 27.110272\n",
      "Epoch [51] True Loss: 140.952561\n",
      "Epoch [52] Model Loss: 27.002590\n",
      "Epoch [52] True Loss: 165.342939\n",
      "Epoch [53] Model Loss: 26.895707\n",
      "Epoch [53] True Loss: 162.752836\n",
      "Epoch [54] Model Loss: 26.787453\n",
      "Epoch [54] True Loss: 144.681324\n",
      "Epoch [55] Model Loss: 26.695210\n",
      "Epoch [55] True Loss: 161.736581\n",
      "Epoch [56] Model Loss: 26.581355\n",
      "Epoch [56] True Loss: 156.503917\n",
      "Epoch [57] Model Loss: 26.529185\n",
      "Epoch [57] True Loss: 173.706689\n",
      "Epoch [58] Model Loss: 26.412077\n",
      "Epoch [58] True Loss: 142.070259\n",
      "Epoch [59] Model Loss: 26.313842\n",
      "Epoch [59] True Loss: 163.163893\n",
      "Epoch [60] Model Loss: 26.223174\n",
      "Epoch [60] True Loss: 165.935468\n",
      "Epoch [61] Model Loss: 26.147234\n",
      "Epoch [61] True Loss: 152.360861\n",
      "Epoch [62] Model Loss: 26.058066\n",
      "Epoch [62] True Loss: 148.227860\n",
      "Epoch [63] Model Loss: 25.983830\n",
      "Epoch [63] True Loss: 157.575629\n",
      "Epoch [64] Model Loss: 25.902931\n",
      "Epoch [64] True Loss: 143.307205\n",
      "Epoch [65] Model Loss: 25.825511\n",
      "Epoch [65] True Loss: 159.939288\n",
      "Epoch [66] Model Loss: 25.758877\n",
      "Epoch [66] True Loss: 142.247317\n",
      "Epoch [67] Model Loss: 25.676426\n",
      "Epoch [67] True Loss: 137.253778\n",
      "Epoch [68] Model Loss: 25.595990\n",
      "Epoch [68] True Loss: 159.396214\n",
      "Epoch [69] Model Loss: 25.543702\n",
      "Epoch [69] True Loss: 147.027082\n",
      "Epoch [70] Model Loss: 25.470537\n",
      "Epoch [70] True Loss: 153.921284\n",
      "Epoch [71] Model Loss: 25.411724\n",
      "Epoch [71] True Loss: 137.887527\n",
      "Epoch [72] Model Loss: 25.347880\n",
      "Epoch [72] True Loss: 129.291446\n",
      "Epoch [73] Model Loss: 25.289333\n",
      "Epoch [73] True Loss: 157.523267\n",
      "Epoch [74] Model Loss: 25.222152\n",
      "Epoch [74] True Loss: 142.740472\n",
      "Epoch [75] Model Loss: 25.172218\n",
      "Epoch [75] True Loss: 143.371659\n",
      "Epoch [76] Model Loss: 25.112220\n",
      "Epoch [76] True Loss: 140.805915\n",
      "Epoch [77] Model Loss: 25.046429\n",
      "Epoch [77] True Loss: 132.598184\n",
      "Epoch [78] Model Loss: 24.997868\n",
      "Epoch [78] True Loss: 148.748558\n",
      "Epoch [79] Model Loss: 24.933292\n",
      "Epoch [79] True Loss: 118.024265\n",
      "Epoch [80] Model Loss: 24.890320\n",
      "Epoch [80] True Loss: 137.170031\n",
      "Epoch [81] Model Loss: 24.838301\n",
      "Epoch [81] True Loss: 135.679500\n",
      "Epoch [82] Model Loss: 24.766601\n",
      "Epoch [82] True Loss: 133.850277\n",
      "Epoch [83] Model Loss: 24.711429\n",
      "Epoch [83] True Loss: 142.017428\n",
      "Epoch [84] Model Loss: 24.654587\n",
      "Epoch [84] True Loss: 134.744307\n",
      "Epoch [85] Model Loss: 24.592715\n",
      "Epoch [85] True Loss: 138.292944\n",
      "Epoch [86] Model Loss: 24.534637\n",
      "Epoch [86] True Loss: 146.068967\n",
      "Epoch [87] Model Loss: 24.474414\n",
      "Epoch [87] True Loss: 143.467676\n",
      "Epoch [88] Model Loss: 24.416342\n",
      "Epoch [88] True Loss: 133.670667\n",
      "Epoch [89] Model Loss: 24.357745\n",
      "Epoch [89] True Loss: 129.451838\n",
      "Epoch [90] Model Loss: 24.299845\n",
      "Epoch [90] True Loss: 151.053331\n",
      "Epoch [91] Model Loss: 24.220690\n",
      "Epoch [91] True Loss: 143.636887\n",
      "Epoch [92] Model Loss: 24.156255\n",
      "Epoch [92] True Loss: 134.179827\n",
      "Epoch [93] Model Loss: 24.091068\n",
      "Epoch [93] True Loss: 146.026625\n",
      "Epoch [94] Model Loss: 24.024864\n",
      "Epoch [94] True Loss: 133.919226\n",
      "Epoch [95] Model Loss: 23.981182\n",
      "Epoch [95] True Loss: 136.634669\n",
      "Epoch [96] Model Loss: 23.902615\n",
      "Epoch [96] True Loss: 136.145210\n",
      "Epoch [97] Model Loss: 23.794968\n",
      "Epoch [97] True Loss: 132.549823\n",
      "Epoch [98] Model Loss: 23.707337\n",
      "Epoch [98] True Loss: 137.504213\n",
      "Epoch [99] Model Loss: 23.618166\n",
      "Epoch [99] True Loss: 135.903083\n",
      "Pretrain Dsicriminator ...\n",
      "Epoch [0], loss: 1.099621\n",
      "Epoch [0], loss: 1.036373\n",
      "Epoch [0], loss: 1.034736\n",
      "Epoch [1], loss: 1.039216\n",
      "Epoch [1], loss: 1.035187\n",
      "Epoch [1], loss: 1.034404\n",
      "Epoch [2], loss: 1.036306\n",
      "Epoch [2], loss: 1.033447\n",
      "Epoch [2], loss: 1.032230\n",
      "Epoch [3], loss: 1.036265\n",
      "Epoch [3], loss: 1.027186\n",
      "Epoch [3], loss: 1.020400\n",
      "Epoch [4], loss: 1.023511\n",
      "Epoch [4], loss: 1.021546\n",
      "Epoch [4], loss: 1.009640\n",
      "#####################################################\n",
      "Start Adeversatial Training...\n",
      "\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [0] True Loss: 130.720277\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [1] True Loss: 117.544625\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [2] True Loss: 131.935511\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [3] True Loss: 125.727868\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [4] True Loss: 140.123870\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [5] True Loss: 118.048805\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [6] True Loss: 129.537977\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [7] True Loss: 125.199846\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [8] True Loss: 133.162360\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [9] True Loss: 136.719850\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [10] True Loss: 145.612561\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [11] True Loss: 132.417349\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [12] True Loss: 123.366230\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [13] True Loss: 136.529488\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [14] True Loss: 133.439112\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [15] True Loss: 131.606579\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [16] True Loss: 131.157520\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [17] True Loss: 111.748456\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [18] True Loss: 135.970236\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [19] True Loss: 125.856231\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [20] True Loss: 140.274421\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [21] True Loss: 136.254448\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [22] True Loss: 120.800029\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [23] True Loss: 118.070366\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [24] True Loss: 110.673925\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [25] True Loss: 130.053718\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [26] True Loss: 111.015261\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [27] True Loss: 115.337853\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [28] True Loss: 121.523246\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [29] True Loss: 125.376145\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [30] True Loss: 123.161628\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [31] True Loss: 116.391825\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [32] True Loss: 121.807401\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [33] True Loss: 122.547109\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [34] True Loss: 114.612255\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [35] True Loss: 117.098143\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [36] True Loss: 116.058692\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [37] True Loss: 121.558657\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [38] True Loss: 120.702088\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [39] True Loss: 119.944802\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [40] True Loss: 128.657078\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [41] True Loss: 124.353073\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [42] True Loss: 121.600514\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [43] True Loss: 115.598229\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [44] True Loss: 119.247353\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [45] True Loss: 127.868782\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [46] True Loss: 127.739586\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [47] True Loss: 124.950847\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [48] True Loss: 119.529321\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [49] True Loss: 112.718555\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [50] True Loss: 125.545508\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [51] True Loss: 117.948145\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [52] True Loss: 106.122459\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [53] True Loss: 104.587240\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [54] True Loss: 106.843257\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [55] True Loss: 109.773546\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [56] True Loss: 113.290270\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [57] True Loss: 119.566260\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [58] True Loss: 108.371019\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [59] True Loss: 115.183469\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [60] True Loss: 115.219120\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [61] True Loss: 103.359298\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [62] True Loss: 98.702724\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [63] True Loss: 98.954938\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [64] True Loss: 111.641882\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [65] True Loss: 109.444847\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [66] True Loss: 104.333654\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [67] True Loss: 108.475919\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [68] True Loss: 126.102524\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [69] True Loss: 112.263475\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [70] True Loss: 100.574906\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [71] True Loss: 104.745051\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [72] True Loss: 117.327129\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [73] True Loss: 118.075714\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [74] True Loss: 97.418182\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [75] True Loss: 97.332469\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [76] True Loss: 105.063643\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [77] True Loss: 100.959928\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [78] True Loss: 105.211386\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [79] True Loss: 103.936411\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [80] True Loss: 105.166495\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [81] True Loss: 105.672642\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [82] True Loss: 100.388810\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [83] True Loss: 107.611636\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [84] True Loss: 97.669722\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [85] True Loss: 98.646168\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [86] True Loss: 113.094775\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [87] True Loss: 98.760395\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [88] True Loss: 110.921921\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [89] True Loss: 97.214376\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [90] True Loss: 107.450838\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [91] True Loss: 107.387682\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [92] True Loss: 101.302166\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [93] True Loss: 112.402957\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [94] True Loss: 102.808232\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [95] True Loss: 110.553351\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [96] True Loss: 109.599587\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [97] True Loss: 99.192518\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [98] True Loss: 104.947379\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [99] True Loss: 115.164193\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [100] True Loss: 99.976882\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [101] True Loss: 118.797802\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [102] True Loss: 99.191667\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [103] True Loss: 104.560313\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [104] True Loss: 123.177545\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [105] True Loss: 101.633885\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [106] True Loss: 110.316752\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [107] True Loss: 115.387692\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [108] True Loss: 107.719602\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [109] True Loss: 112.875663\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [110] True Loss: 113.787759\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [111] True Loss: 99.461918\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [112] True Loss: 122.819836\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [113] True Loss: 110.707442\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [114] True Loss: 109.435506\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [115] True Loss: 105.869189\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [116] True Loss: 104.418512\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [117] True Loss: 112.221995\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [118] True Loss: 101.533955\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [119] True Loss: 105.487123\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [120] True Loss: 107.526285\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [121] True Loss: 97.717051\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [122] True Loss: 89.566151\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [123] True Loss: 99.828683\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [124] True Loss: 92.392852\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [125] True Loss: 93.684855\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [126] True Loss: 95.278500\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [127] True Loss: 87.563892\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [128] True Loss: 95.854681\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [129] True Loss: 101.280866\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [130] True Loss: 89.985974\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [131] True Loss: 86.144866\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [132] True Loss: 100.163266\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [133] True Loss: 91.486942\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [134] True Loss: 88.096613\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [135] True Loss: 95.471555\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [136] True Loss: 88.649862\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [137] True Loss: 94.919762\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [138] True Loss: 100.347747\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [139] True Loss: 93.436181\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [140] True Loss: 93.224212\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [141] True Loss: 89.333650\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [142] True Loss: 96.064386\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [143] True Loss: 91.998247\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [144] True Loss: 81.122304\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [145] True Loss: 91.744732\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [146] True Loss: 87.971812\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [147] True Loss: 74.887866\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [148] True Loss: 96.036631\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [149] True Loss: 93.954931\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [150] True Loss: 91.562269\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [151] True Loss: 90.107058\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [152] True Loss: 91.980789\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [153] True Loss: 86.021354\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [154] True Loss: 83.937046\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [155] True Loss: 85.229392\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [156] True Loss: 91.806480\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [157] True Loss: 89.341105\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [158] True Loss: 93.555171\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [159] True Loss: 87.542976\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [160] True Loss: 94.427063\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [161] True Loss: 84.669304\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [162] True Loss: 93.833732\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [163] True Loss: 88.367348\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [164] True Loss: 88.847363\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [165] True Loss: 98.863111\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [166] True Loss: 87.827545\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [167] True Loss: 99.036319\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [168] True Loss: 108.087641\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [169] True Loss: 100.210131\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [170] True Loss: 85.882783\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [171] True Loss: 88.544711\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [172] True Loss: 86.086187\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [173] True Loss: 87.953022\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [174] True Loss: 80.340845\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [175] True Loss: 89.972545\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [176] True Loss: 92.961999\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [177] True Loss: 89.448055\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [178] True Loss: 81.752161\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [179] True Loss: 86.422377\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [180] True Loss: 95.160267\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [181] True Loss: 87.168419\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [182] True Loss: 88.489967\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [183] True Loss: 85.292287\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [184] True Loss: 85.253089\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [185] True Loss: 94.998413\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [186] True Loss: 91.770196\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [187] True Loss: 80.153157\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [188] True Loss: 92.234341\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [189] True Loss: 84.311546\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [190] True Loss: 83.499245\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [191] True Loss: 97.074298\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [192] True Loss: 94.219001\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [193] True Loss: 85.273661\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [194] True Loss: 85.237887\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [195] True Loss: 78.883561\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [196] True Loss: 79.116173\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [197] True Loss: 93.022837\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [198] True Loss: 83.822454\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [199] True Loss: 89.364155\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import argparse\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from lib.seqgan.generator import Generator\n",
    "from lib.seqgan.discriminator import Discriminator\n",
    "from lib.seqgan.target_lstm import TargetLSTM\n",
    "from lib.seqgan.rollout import Rollout\n",
    "from lib.seqgan.data_iter import GenDataIter, DisDataIter\n",
    "opt = edict()\n",
    "opt.cuda = None\n",
    "# Basic Training Paramters\n",
    "SEED = 88\n",
    "BATCH_SIZE = 16\n",
    "TOTAL_BATCH = 200\n",
    "GENERATED_NUM = 100\n",
    "POSITIVE_FILE = 'real.data'\n",
    "NEGATIVE_FILE = 'gene.data'\n",
    "EVAL_FILE = 'eval.data'\n",
    "VOCAB_SIZE = 50\n",
    "PRE_EPOCH_NUM = 100 #120\n",
    "\n",
    "if opt.cuda is not None and opt.cuda >= 0:\n",
    "    torch.cuda.set_device(opt.cuda)\n",
    "    opt.cuda = True\n",
    "\n",
    "# Genrator Parameters\n",
    "g_emb_dim = 32\n",
    "g_hidden_dim = 32\n",
    "g_sequence_len = 20\n",
    "\n",
    "# Discriminator Parameters\n",
    "d_emb_dim = 64\n",
    "d_filter_sizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]\n",
    "d_num_filters = [100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160]\n",
    "\n",
    "d_dropout = 0.75\n",
    "d_num_class = 2\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def generate_samples(model, batch_size, generated_num, output_file):\n",
    "    samples = []\n",
    "    for _ in range(int(generated_num / batch_size)):\n",
    "        sample = model.sample(batch_size, g_sequence_len).cpu().data.numpy().tolist()\n",
    "        samples.extend(sample)\n",
    "    with open(output_file, 'w') as fout:\n",
    "        for sample in samples:\n",
    "            string = ' '.join([str(s) for s in sample])\n",
    "            fout.write('%s\\n' % string)\n",
    "            \n",
    "def train_epoch(model, data_iter, criterion, optimizer):\n",
    "    total_loss = 0.\n",
    "    total_words = 0.\n",
    "    for (data, target) in data_iter:\n",
    "        #tqdm(data_iter, mininterval=2, desc=' - Training', leave=False):\n",
    "        data = Variable(data)\n",
    "        target = Variable(target)\n",
    "        if opt.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        target = target.contiguous().view(-1)\n",
    "        pred = model.forward(data)\n",
    "        loss = criterion(pred, target)\n",
    "        total_loss += loss.data[0]\n",
    "        total_words += data.size(0) * data.size(1)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    data_iter.reset()\n",
    "    return math.exp(total_loss / total_words)\n",
    "\n",
    "def eval_epoch(model, data_iter, criterion):\n",
    "    total_loss = 0.\n",
    "    total_words = 0.\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in data_iter:#tqdm(\n",
    "            #data_iter, mininterval=2, desc=' - Training', leave=False):\n",
    "            data = Variable(data)\n",
    "            target = Variable(target)\n",
    "            if opt.cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            target = target.contiguous().view(-1)\n",
    "            pred = model.forward(data)\n",
    "            loss = criterion(pred, target)\n",
    "            total_loss += loss.data[0]\n",
    "            total_words += data.size(0) * data.size(1)\n",
    "        data_iter.reset()\n",
    "    return math.exp(total_loss / total_words)\n",
    "            \n",
    "class GANLoss(nn.Module):\n",
    "    \"\"\"Reward-Refined NLLLoss Function for adversial training of Gnerator\"\"\"\n",
    "    def __init__(self):\n",
    "        super(GANLoss, self).__init__()\n",
    "\n",
    "    def forward(self, prob, target, reward):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            prob: (N, C), torch Variable \n",
    "            target : (N, ), torch Variable\n",
    "            reward : (N, ), torch Variable\n",
    "        \"\"\"\n",
    "        N = target.size(0)\n",
    "        C = prob.size(1)\n",
    "        one_hot = torch.zeros((N, C))\n",
    "        if prob.is_cuda:\n",
    "            one_hot = one_hot.cuda()\n",
    "        # https://blog.csdn.net/victoriaw/article/details/72874637 把索引标签转换成one-hot标签表示\n",
    "        one_hot.scatter_(1, target.data.view((-1,1)), 1)\n",
    "        one_hot = one_hot.type(torch.ByteTensor)\n",
    "        one_hot = Variable(one_hot)\n",
    "        if prob.is_cuda:\n",
    "            one_hot = one_hot.cuda()\n",
    "        # masked_select 取掩码值，返回的是一维向量, 即每个正确值对应的generator预测的概率\n",
    "        # loss 的目的是提高generator prob预测的概率\n",
    "        loss = torch.masked_select(prob, one_hot)\n",
    "        loss = loss.view(reward.size(0),-1)\n",
    "        \n",
    "        loss = loss * reward\n",
    "        # 因为 prob 是通过 nn.LogSoftmax输出的，所以要增加选中概率，需要采用负对数方式\n",
    "        # 即 argmax(a) =  -log(a)  在a取0到1之间，这样的目的是a越大， loss越小\n",
    "        loss =  -torch.sum(loss)\n",
    "        return loss\n",
    "\n",
    "# Define Networks\n",
    "# VOCAB_SIZE = 5000, g_emb_dim = 32, g_hidden_dim = 32\n",
    "generator = Generator(VOCAB_SIZE, g_emb_dim, g_hidden_dim, opt.cuda)\n",
    "# d_emb_dim = 64\n",
    "# d_filter_sizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]\n",
    "# d_num_filters = [100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160]\n",
    "discriminator = Discriminator(d_num_class, VOCAB_SIZE, d_emb_dim, d_filter_sizes, d_num_filters, d_dropout)\n",
    "target_lstm = TargetLSTM(VOCAB_SIZE, g_emb_dim, g_hidden_dim, opt.cuda)\n",
    "\n",
    "print('Generating data ...')\n",
    "generate_samples(target_lstm, BATCH_SIZE, GENERATED_NUM, POSITIVE_FILE)\n",
    "\n",
    "# Load data from file\n",
    "gen_data_iter = GenDataIter(POSITIVE_FILE, BATCH_SIZE)\n",
    "\n",
    "# Pretrain Generator using MLE\n",
    "gen_criterion = nn.NLLLoss(size_average=False)\n",
    "gen_optimizer = optim.Adam(generator.parameters())\n",
    "\n",
    "print('Pretrain with MLE ...')  # ？？？？\n",
    "for epoch in range(PRE_EPOCH_NUM):\n",
    "    loss = train_epoch(generator, gen_data_iter, gen_criterion, gen_optimizer)\n",
    "    print('Epoch [%d] Model Loss: %f'% (epoch, loss))\n",
    "    generate_samples(generator, BATCH_SIZE, GENERATED_NUM, EVAL_FILE)\n",
    "    eval_iter = GenDataIter(EVAL_FILE, BATCH_SIZE)\n",
    "    loss = eval_epoch(target_lstm, eval_iter, gen_criterion)\n",
    "    print('Epoch [%d] True Loss: %f' % (epoch, loss))\n",
    "\n",
    "# Pretrain Discriminator\n",
    "dis_criterion = nn.NLLLoss(size_average=False)\n",
    "dis_optimizer = optim.Adam(discriminator.parameters())\n",
    "if opt.cuda:\n",
    "    dis_criterion = dis_criterion.cuda()\n",
    "    \n",
    "print('Pretrain Dsicriminator ...')\n",
    "for epoch in range(5):\n",
    "    generate_samples(generator, BATCH_SIZE, GENERATED_NUM, NEGATIVE_FILE)\n",
    "    dis_data_iter = DisDataIter(POSITIVE_FILE, NEGATIVE_FILE, BATCH_SIZE)\n",
    "    for _ in range(3):\n",
    "        loss = train_epoch(discriminator, dis_data_iter, dis_criterion, dis_optimizer)\n",
    "        print('Epoch [%d], loss: %f' % (epoch, loss))\n",
    "\n",
    "# Adversarial Training 对抗训练\n",
    "rollout = Rollout(generator, 0.8)    \n",
    "print('#####################################################')\n",
    "print('Start Adeversatial Training...\\n')\n",
    "gen_gan_loss = GANLoss()\n",
    "gen_gan_optm = optim.Adam(generator.parameters())\n",
    "if opt.cuda:\n",
    "    gen_gan_loss = gen_gan_loss.cuda()\n",
    "gen_criterion = nn.NLLLoss(size_average=False)\n",
    "if opt.cuda:\n",
    "    gen_criterion = gen_criterion.cuda()\n",
    "dis_criterion = nn.NLLLoss(size_average=False)\n",
    "dis_optimizer = optim.Adam(discriminator.parameters())\n",
    "if opt.cuda:\n",
    "    dis_criterion = dis_criterion.cuda()\n",
    "\n",
    "\n",
    "if opt.cuda:\n",
    "    dis_criterion = dis_criterion.cuda()\n",
    "for total_batch in range(TOTAL_BATCH):\n",
    "    ## Train the generator for one step\n",
    "    for it in range(1):\n",
    "        samples = generator.sample(BATCH_SIZE, g_sequence_len)\n",
    "        # construct the input to the genrator, add zeros before samples and delete the last column\n",
    "        zeros = torch.zeros((BATCH_SIZE, 1)).type(torch.LongTensor)\n",
    "        if samples.is_cuda:\n",
    "            zeros = zeros.cuda()\n",
    "        inputs = Variable(torch.cat([zeros, samples.data], dim = 1)[:, :-1].contiguous())\n",
    "        targets = Variable(samples.data).contiguous().view((-1,))\n",
    "        # calculate the reward, 16是作蒙特卡罗搜索次数 ， 确认一下\n",
    "        rewards = rollout.get_reward(samples, 16, discriminator)\n",
    "        rewards = Variable(torch.Tensor(rewards))\n",
    "        if opt.cuda:\n",
    "            rewards = torch.exp(rewards.cuda()).contiguous().view((-1,))\n",
    "        prob = generator.forward(inputs)\n",
    "        loss = gen_gan_loss(prob, targets, rewards)\n",
    "        gen_gan_optm.zero_grad()\n",
    "        loss.backward()\n",
    "        gen_gan_optm.step()\n",
    "        \n",
    "    if total_batch % 1 == 0 or total_batch == TOTAL_BATCH - 1:\n",
    "        generate_samples(generator, BATCH_SIZE, GENERATED_NUM, EVAL_FILE)\n",
    "        eval_iter = GenDataIter(EVAL_FILE, BATCH_SIZE)\n",
    "        loss = eval_epoch(target_lstm, eval_iter, gen_criterion)\n",
    "        print('Batch [%d] True Loss: %f' % (total_batch, loss))\n",
    "    rollout.update_params()\n",
    "\n",
    "    for _ in range(4):\n",
    "        generate_samples(generator, BATCH_SIZE, GENERATED_NUM, NEGATIVE_FILE)\n",
    "        dis_data_iter = DisDataIter(POSITIVE_FILE, NEGATIVE_FILE, BATCH_SIZE)\n",
    "        for _ in range(2):\n",
    "            loss = train_epoch(discriminator, dis_data_iter, dis_criterion, dis_optimizer)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "gen_data_iter = GenDataIter(POSITIVE_FILE, BATCH_SIZE)\n",
    "data,target = next(gen_data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project_tw\\anly\\venv\\lib\\site-packages\\ipykernel_launcher.py:96: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [0] True Loss: 112.853114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project_tw\\anly\\venv\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [1] True Loss: 136.981263\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [2] True Loss: 143.709232\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [3] True Loss: 115.692140\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [4] True Loss: 132.196034\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [5] True Loss: 115.073619\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [6] True Loss: 117.512569\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [7] True Loss: 129.077202\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [8] True Loss: 128.294591\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [9] True Loss: 123.369054\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [10] True Loss: 132.249058\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [11] True Loss: 128.147853\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [12] True Loss: 125.959675\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [13] True Loss: 119.040102\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [14] True Loss: 117.266220\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [15] True Loss: 108.139142\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [16] True Loss: 109.471831\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [17] True Loss: 106.330185\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [18] True Loss: 112.488371\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [19] True Loss: 105.106185\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [20] True Loss: 100.071796\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [21] True Loss: 94.920033\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [22] True Loss: 98.012024\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [23] True Loss: 91.561090\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [24] True Loss: 96.279324\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [25] True Loss: 98.679147\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [26] True Loss: 95.480296\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [27] True Loss: 70.838672\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [28] True Loss: 81.918669\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [29] True Loss: 71.367479\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [30] True Loss: 68.776633\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [31] True Loss: 70.725773\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [32] True Loss: 69.840522\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [33] True Loss: 67.166639\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [34] True Loss: 62.658068\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [35] True Loss: 63.436396\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [36] True Loss: 53.143270\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [37] True Loss: 45.499554\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [38] True Loss: 49.038632\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [39] True Loss: 45.781756\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [40] True Loss: 48.916443\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [41] True Loss: 45.207223\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [42] True Loss: 32.788723\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [43] True Loss: 45.026887\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [44] True Loss: 37.316312\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [45] True Loss: 39.102544\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [46] True Loss: 39.660644\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [47] True Loss: 36.505934\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [48] True Loss: 34.658267\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [49] True Loss: 37.117428\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [50] True Loss: 26.655899\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [51] True Loss: 31.229044\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [52] True Loss: 29.679998\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [53] True Loss: 27.878435\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [54] True Loss: 26.955152\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [55] True Loss: 24.254547\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [56] True Loss: 24.781309\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [57] True Loss: 24.101282\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [58] True Loss: 24.856837\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [59] True Loss: 22.312858\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [60] True Loss: 22.515548\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [61] True Loss: 16.844580\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [62] True Loss: 23.408396\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [63] True Loss: 21.848561\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [64] True Loss: 22.397699\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [65] True Loss: 20.086341\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [66] True Loss: 18.330988\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [67] True Loss: 14.315503\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [68] True Loss: 16.411342\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [69] True Loss: 15.562312\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [70] True Loss: 16.358702\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [71] True Loss: 14.261664\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [72] True Loss: 14.950604\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [73] True Loss: 16.139228\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [74] True Loss: 16.564047\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [75] True Loss: 16.569478\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [76] True Loss: 13.652278\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [77] True Loss: 15.020575\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [78] True Loss: 14.587205\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [79] True Loss: 14.571035\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [80] True Loss: 11.608315\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [81] True Loss: 13.302366\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [82] True Loss: 15.694790\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [83] True Loss: 11.882935\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [84] True Loss: 11.966801\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [85] True Loss: 12.355726\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [86] True Loss: 11.759208\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [87] True Loss: 13.639811\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [88] True Loss: 12.301609\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [89] True Loss: 10.782724\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [90] True Loss: 13.275622\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [91] True Loss: 14.329644\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [92] True Loss: 11.147947\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [93] True Loss: 11.633498\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [94] True Loss: 9.590239\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [95] True Loss: 12.375730\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [96] True Loss: 12.113510\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [97] True Loss: 9.867484\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [98] True Loss: 12.971738\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [99] True Loss: 10.519992\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [100] True Loss: 11.031383\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [101] True Loss: 10.490060\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [102] True Loss: 13.613394\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [103] True Loss: 9.510200\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [104] True Loss: 12.932973\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [105] True Loss: 12.492835\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [106] True Loss: 10.394466\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [107] True Loss: 9.633686\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [108] True Loss: 9.456562\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [109] True Loss: 10.213864\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [110] True Loss: 10.860637\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [111] True Loss: 9.979268\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [112] True Loss: 8.466044\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [113] True Loss: 10.474994\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [114] True Loss: 10.345180\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [115] True Loss: 7.846126\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [116] True Loss: 9.087108\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [117] True Loss: 10.032746\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [118] True Loss: 9.508298\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [119] True Loss: 8.550603\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [120] True Loss: 8.494894\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [121] True Loss: 7.292092\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [122] True Loss: 7.455140\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [123] True Loss: 8.227467\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [124] True Loss: 6.765860\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [125] True Loss: 7.134091\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [126] True Loss: 5.371972\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [127] True Loss: 6.544243\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [128] True Loss: 7.035922\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [129] True Loss: 7.878129\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [130] True Loss: 7.930943\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [131] True Loss: 8.960342\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [132] True Loss: 6.394277\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [133] True Loss: 9.900895\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [134] True Loss: 6.604816\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [135] True Loss: 5.726131\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [136] True Loss: 6.991139\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [137] True Loss: 5.517080\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [138] True Loss: 5.625371\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [139] True Loss: 5.248198\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [140] True Loss: 5.989224\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [141] True Loss: 5.874027\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [142] True Loss: 6.922995\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [143] True Loss: 6.004932\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [144] True Loss: 5.338641\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [145] True Loss: 5.228645\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [146] True Loss: 6.694992\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [147] True Loss: 6.091513\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [148] True Loss: 5.772564\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [149] True Loss: 5.517205\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [150] True Loss: 5.753767\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [151] True Loss: 5.767311\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [152] True Loss: 7.414608\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [153] True Loss: 5.830672\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [154] True Loss: 5.166888\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [155] True Loss: 5.095129\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [156] True Loss: 4.629726\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [157] True Loss: 4.727833\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [158] True Loss: 6.154750\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [159] True Loss: 5.326407\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [160] True Loss: 6.004184\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [161] True Loss: 4.193599\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [162] True Loss: 5.569060\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [163] True Loss: 4.431776\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [164] True Loss: 4.873929\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [165] True Loss: 4.410783\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [166] True Loss: 5.242745\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [167] True Loss: 5.942555\n",
      "loss size --> torch.Size([16, 20])\n",
      "reward size -->torch.Size([16, 20])\n",
      "Batch [168] True Loss: 4.283301\n"
     ]
    }
   ],
   "source": [
    "for total_batch in range(TOTAL_BATCH):\n",
    "    ## Train the generator for one step\n",
    "    for it in range(1):\n",
    "        samples = generator.sample(BATCH_SIZE, g_sequence_len)\n",
    "        # construct the input to the genrator, add zeros before samples and delete the last column\n",
    "        zeros = torch.zeros((BATCH_SIZE, 1)).type(torch.LongTensor)\n",
    "        if samples.is_cuda:\n",
    "            zeros = zeros.cuda()\n",
    "        inputs = Variable(torch.cat([zeros, samples.data], dim = 1)[:, :-1].contiguous())\n",
    "        targets = Variable(samples.data).contiguous().view((-1,))\n",
    "        # calculate the reward, 16是作蒙特卡罗搜索次数 ， 确认一下\n",
    "        rewards = rollout.get_reward(samples, 16, discriminator)\n",
    "        rewards = Variable(torch.Tensor(rewards))\n",
    "        if opt.cuda:\n",
    "            rewards = torch.exp(rewards.cuda()).contiguous().view((-1,))\n",
    "        prob = generator.forward(inputs)\n",
    "        loss = gen_gan_loss(prob, targets, rewards)\n",
    "        gen_gan_optm.zero_grad()\n",
    "        loss.backward()\n",
    "        gen_gan_optm.step()\n",
    "        \n",
    "    if total_batch % 1 == 0 or total_batch == TOTAL_BATCH - 1:\n",
    "        generate_samples(generator, BATCH_SIZE, GENERATED_NUM, EVAL_FILE)\n",
    "        eval_iter = GenDataIter(EVAL_FILE, BATCH_SIZE)\n",
    "        loss = eval_epoch(target_lstm, eval_iter, gen_criterion)\n",
    "        print('Batch [%d] True Loss: %f' % (total_batch, loss))\n",
    "    rollout.update_params()\n",
    "\n",
    "    for _ in range(4):\n",
    "        generate_samples(generator, BATCH_SIZE, GENERATED_NUM, NEGATIVE_FILE)\n",
    "        dis_data_iter = DisDataIter(POSITIVE_FILE, NEGATIVE_FILE, BATCH_SIZE)\n",
    "        for _ in range(2):\n",
    "            loss = train_epoch(discriminator, dis_data_iter, dis_criterion, dis_optimizer)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
