{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stock\n",
    "from stock.common.sdata import StockData\n",
    "sd = StockData(code='600016')\n",
    "data  = sd.combine_income(ndays=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算N天的最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hecong/venv/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "dd = sd.datas.tail(10)\n",
    "Open,Close,Low,High = dd.Open,dd.Close,dd.Low,dd.High\n",
    "shift_num = -1\n",
    "Income = ((((Close.shift(shift_num).values + Low.shift(shift_num).values + High.shift(shift_num).values)/3)/Close) -1) * 100\n",
    "ndays = 5\n",
    "columns = []\n",
    "for i in range(ndays):\n",
    "    shift_num = 0 - (i+1)\n",
    "    columns.append('IM_'+str(i+1))\n",
    "    dd['IM_'+str(i+1)]= ((((Close.shift(shift_num).values + Low.shift(shift_num).values + High.shift(shift_num).values )/3)/Close) -1) * 100\n",
    "dd = dd.dropna(axis=0,how='any') \n",
    "dd['INCOME'] = dd[columns].max(axis=1)\n",
    "# for key in columns:\n",
    "#     del dd[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Open  High  Close   Low    Volume      Amount    INCOME  Flag  \\\n",
      "Date                                                                        \n",
      "2018-05-21  7.94  7.98   7.94  7.93  55498235  44136736.0 -0.587741     0   \n",
      "2018-05-22  7.95  7.96   7.88  7.84  65749035  51775721.6 -0.846024     0   \n",
      "2018-05-23  7.87  7.87   7.79  7.78  61488114  48075734.4  0.299529     0   \n",
      "2018-05-24  7.79  7.86   7.81  7.77  42686010  33378304.0 -0.085361     0   \n",
      "2018-05-25  7.83  7.85   7.78  7.76  31007140  24187774.4  0.299914     0   \n",
      "\n",
      "                IM_1      IM_2      IM_3      IM_4      IM_5  \n",
      "Date                                                          \n",
      "2018-05-21 -0.587741 -1.595298 -1.595298 -1.805206 -1.721243  \n",
      "2018-05-22 -0.846024 -0.846024 -1.057530 -0.972927 -1.269036  \n",
      "2018-05-23  0.299529  0.085580  0.171160 -0.128370 -1.626016  \n",
      "2018-05-24 -0.170721 -0.085361 -0.384123 -1.877934 -1.835254  \n",
      "2018-05-25  0.299914  0.000000 -1.499572 -1.456727 -1.071123  \n"
     ]
    }
   ],
   "source": [
    "print(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本统计信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    https://blog.csdn.net/qq_39521554/article/details/79574561\n",
    "    https://blog.csdn.net/cymy001/article/details/78300900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag = 0 291\n",
      "flag = 1 1081\n",
      "flag = 2 1484\n"
     ]
    }
   ],
   "source": [
    "# 通过dataframe group by 显示\n",
    "print('flag = 0', len(data.groupby('Flag').groups[0]))\n",
    "print('flag = 1', len(data.groupby('Flag').groups[1]))\n",
    "print('flag = 2', len(data.groupby('Flag').groups[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    https://www.zhihu.com/question/20467170    标准化和归一化什么区别？\n",
    "    \n",
    "    http://www.cnblogs.com/zhaokui/p/5112287.html   归一化与标准化\n",
    "    \n",
    "    https://blog.csdn.net/zbc1090549839/article/details/44755451    时间序列的归一化方法\n",
    "    \n",
    "    https://machinelearningmastery.com/normalize-standardize-time-series-data-python/ How to Normalize and Standardize Time Series Data in Python\n",
    "    \n",
    "    \n",
    "    归一化（Normalization）与标准化（Standardization）\n",
    "    \n",
    "    A. 归一化\n",
    "    特点\n",
    "        对不同特征维度的伸缩变换的目的是使各个特征维度对目标函数的影响权重是一致的，即使得那些扁平分布的数据伸缩变换成类圆形。这也就改变了原始数据的一个分布。归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为标量。 在多种计算中都经常用到这种方法。\n",
    "\n",
    "    好处：\n",
    "        1 提高迭代求解的收敛速度\n",
    "        2 提高迭代求解的精度        \n",
    "    \n",
    "    B. 标准化\n",
    "    特点\n",
    "        对不同特征维度的伸缩变换的目的是使得不同度量之间的特征具有可比性。同时不改变原始数据的分布。数据的标准化（normalization）是将数据按比例缩放，使之落入一个小的特定区间。在某些比较和评价的指标处理中经常会用到，去除数据的单位限制，将其转化为无量纲的纯数值，便于不同单位或量级的指标能够进行比较和加权。\n",
    "\n",
    "    好处\n",
    "        1 使得不同度量之间的特征具有可比性，对目标函数的影响体现在几何分布上，而不是数值上\n",
    "        2 不改变原始数据的分布\n",
    "        \n",
    "        \n",
    "        \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data_in, target = StockData.package_data(data)\n",
    "# scale = StandardScaler()\n",
    "# data_scale = [scale.fit_transform(x.values) for x in data_in]\n",
    "\n",
    "# 因数据每天都有新增变化， 所以暂时先不使用数据标准化、归一化处理，只是将数据做np.log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
