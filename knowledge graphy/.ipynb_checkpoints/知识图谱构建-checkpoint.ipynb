{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据源"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://wenku.baidu.com/view/c9f4e5e67f1922791788e82a.html\n",
    "https://wenku.baidu.com/view/dd6b730c76c66137ee06199e.html\n",
    "https://wenku.baidu.com/view/328ffe89195f312b3169a5f7.html\n",
    "https://www.sohu.com/a/324251797_818374 !!!!\n",
    "https://wenku.baidu.com/view/c9f4e5e67f1922791788e82a.html ！！！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 相关技术"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    " 对文本进行处理，提取关键词，包括分词技术等，知识图谱基础技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "整理好的 ” 小学生数据知识点.txt\" 基本为半结构化数据， 知识点基本以”：“隔开 前部分是知识点，后部分是内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图谱构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 知识抽取"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "实体结构：\n",
    "  实体名， 属性：（内容描述， 归类）\n",
    "处理流程：\n",
    "一、提取专家半结构化数据进行知识点实体抽取\n",
    "1、 按层级及相对结构化文本的特点提取所有知识点\n",
    "2、 知识点归类、合并， （暂时合并不需要，合并主要针对两个实体代表同一实体的情况下）。归类暂时先通过导级关系进行归类，根据实际情况再通过SVM类似的方法进行处理。\n",
    "二、扩展方式\n",
    "1、实体通过百度百科类似的搜索引擎查找方式进行扩展。  （略）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 结构化内容中获取实体 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n注意生成的csv文件需保存到 neo4j 应用目录import 下\\n执行脚本：\\nLOAD CSV WITH HEADERS FROM \"file:/math.csv\" AS row\\nCREATE (n:Knowledge)\\nset n=row;\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "file_name = 'D:\\\\PROJECT_TW\\\\twedu\\\\解决方案\\\\小学数学知识点.txt'\n",
    "out_file_name = 'D:\\\\PROJECT_TW\\\\twedu\\\\解决方案\\\\小学数学知识点.csv'\n",
    "dict_file_name = \"D:\\\\PROJECT_TW\\\\twedu\\\\解决方案\\\\小学数学知识点字典.txt\"\n",
    "pattern = r'[:|：]' \n",
    "\n",
    "# 得到当前层级数\n",
    "def get_level(line):\n",
    "    ret_level = -1\n",
    "    lev = {\n",
    "        1 : r'第[一|二|三|四|五|六]章',\n",
    "        2 : r'[一|二|三|四|五|六|七|八|九]、',\n",
    "        3 : r'（[一|二|三|四|五|六]）',\n",
    "        4 : r'\\d+、',\n",
    "        5 : r'[⑴|⑵|⑶|⑷|⑸|⑹|⑺|⑻]'}\n",
    "    for key in lev.keys():\n",
    "        if re.match(lev[key],line):\n",
    "            break\n",
    "            \n",
    "    if key:\n",
    "        ret_level = key\n",
    "    return ret_level, lev\n",
    "details = []\n",
    "\n",
    "with open(file_name,'r',encoding='utf-8') as f:\n",
    "    current_lev_map = {}\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n').strip()\n",
    "        if len(line) > 0:\n",
    "            result = re.split(pattern, line, maxsplit=1)\n",
    "            level,lev_define = get_level(line)\n",
    "            result = [x.strip('\\n') for x in result]\n",
    "#             print('level --> ',level, ' result --> ', result[0])\n",
    "            result[0] = re.split(lev_define[level],result[0],maxsplit=1)[1]\n",
    "            current_lev_map[level] = result[0]\n",
    "            up_title = ''\n",
    "            if level >= 2:\n",
    "                up_title = current_lev_map[level-1]\n",
    "            details.append([up_title.strip(), result[0].strip(), result[1].strip() if len(result) > 1 else '' ])\n",
    "#             print('title:{}-->{}'.format(up_title, result))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataframe = pd.DataFrame(np.array(details),columns=['title','name','detail'])\n",
    "dataframe.to_csv(out_file_name,index=False,sep=',',encoding='utf_8_sig')\n",
    "\n",
    "with open(dict_file_name, 'w', encoding='utf-8') as f:\n",
    "    content = dataframe.name.values.tolist()\n",
    "    content.append('圆点')\n",
    "    text = '\\n'.join(content)\n",
    "    f.writelines(text)\n",
    "        \n",
    "print('over !')\n",
    "\n",
    "'''\n",
    "清除所有数据\n",
    "MATCH (n)\n",
    "OPTIONAL MATCH (n)-[r]-()\n",
    "DELETE n,r\n",
    "\n",
    "注意生成的csv文件需保存到 neo4j 应用目录import 下\n",
    "执行脚本：\n",
    "LOAD CSV WITH HEADERS FROM \"file:/math.csv\" AS row\n",
    "CREATE (n:Knowledge)\n",
    "set n=row;\n",
    "'''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非结构化数据抽取实体"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1、https://www.zhihu.com/question/58151047   git 爬虫项目\n",
    "2、https://github.com/Jack-Cherish/python-spider 爬虫项目\n",
    "3、https://github.com/Ehco1996/Python-crawler  爬虫项目\n",
    "4、简单百度百科爬虫实现\n",
    "headers = {'pragma': \"no-cache\",'accept-encoding': \"gzip, deflate, br\",'accept-language': \"zh-CN,zh;q=0.8\",\n",
    "'upgrade-insecure-requests': \"1\",'user-agent': \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36\",'accept': \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",'cache-control': \"no-cache\",\n",
    "'connection': \"keep-alive\",}\n",
    "url = 'https://baike.baidu.com/item/平行四边形'\n",
    "rsp = requests.get(url=url, headers=headers)\n",
    "content = str(rsp.content,'utf-8')\n",
    "\n",
    "处理步骤：\n",
    "1、实体命名识别、实体对齐\n",
    "   实体命名识别： 就是从文本里提取出实体并对每个实体做分类/打标签：比如从上述文本里，我们可以提取出实体-“NYC”，并标记实体类型为 “Location”；我们也可以从中提取出“Virgil's BBQ”，并标记实体类型为“Restarant”。这种过程称之为实体命名识别，这是一项相对比较成熟的技术，有一些现成的工具可以用来做这件事情。\n",
    "   实体对齐： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 关系抽取 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "关系说明：\n",
    "    关系现各类分为： 属于， 前提（即该知识点需要掌握的其它知识点）  \n",
    "处理流程：\n",
    "一、根据提取的专家半结构化数据的数据进行关系抽取\n",
    "1、 按文本中的层级抽取”属于“关系， 注意需关闭某些”概念“这样一类的层级\n",
    "\n",
    "2、 ”前提\"关系的抽取从知识点描述中提取，检测其内容中是否包含其它知识点.  \n",
    "\n",
    "Chaplot  andKoedinger  use  educational  data  to  induce  the  prerequisiterelations among multiple units in a course [2], and Liang et al.recovers prerequisite relations from course dependencies [4].Another group of researchers utilize the observed relationsamong courses to create a directed universal concept graph.  In addition,  we utilize students’performance data rather than course descriptions to identifyrelations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 简单关系抽取（根据知识点文本内容抽取NEXT关系）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "1、根据文档结构建立PARTOF关系\n",
    "执行脚本：\n",
    "MATCH (a:Knowledge), (b:Knowledge) \n",
    "   WHERE a.name = b.title\n",
    "CREATE (a)-[:INCLUDE]->(b) \n",
    "RETURN a,b \n",
    "\n",
    "2、根据CSV知识点内容中检索方式，建立USE关系\n",
    "处理流程（极简流程）：\n",
    "1） 对内容分词，然后通过分词去匹配， 注意（这里关系有可能是引用和使用两种，怎么样进行区分？？？）  分词工具包： https://github.com/lancopku/pkuseg-python\n",
    "'''\n",
    "import pandas as pd\n",
    "import pkuseg\n",
    "import numpy as np\n",
    "from py2neo import Graph\n",
    "dict_file_name = \"D:\\\\PROJECT_TW\\\\twedu\\\\解决方案\\\\小学数学知识点字典.txt\"\n",
    "file_name = 'D:\\\\PROJECT_TW\\\\twedu\\\\解决方案\\\\小学数学知识点.csv'\n",
    "wordseg = pkuseg.pkuseg(user_dict=dict_file_name)\n",
    "dataframe = pd.read_csv(file_name)\n",
    "graph = Graph(uri='bolt://127.0.0.1:7687',auth=('neo4j','654321')) \n",
    "\n",
    "kn_dict = None\n",
    "with open(dict_file_name,'r',encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    kn_dict = [x.strip() for x in lines]\n",
    "kn_dict.remove('圆点')\n",
    "# print(kn_dict)\n",
    "# 检测前置情况, 检测 cut text 是否在包含filter name\n",
    "def is_pre(cut_text,filter_name):\n",
    "    pre_kn = []\n",
    "    cut_text = np.array(cut_text)\n",
    "    for item in kn_dict:\n",
    "        result = np.where(cut_text==item)\n",
    "        if len(result[0]) > 0 and item != filter_name:\n",
    "            pre_kn.append(item)\n",
    "    return pre_kn\n",
    "\n",
    "# 检测两个知识点是否有关系\n",
    "def has_rel(k1, k2):\n",
    "    result = False\n",
    "    rdata = graph.run(\"MATCH (K:Knowledge {name:'%s'}) - [r] -> (P:Knowledge {name:'%s'}) RETURN r\" % (k1,k2)).data()\n",
    "    if (len(rdata) > 0):\n",
    "        result = True\n",
    "    return result\n",
    "\n",
    "# 创建知识点NEXT关系 ， k2 -> NEXT --> k1, K1需要先掌握K2知识点\n",
    "def create_next_rel(k1,k2):\n",
    "    graph.run(\"MATCH (K1:Knowledge {name:'%s'}), (K2:Knowledge {name:'%s'}) CREATE (K2) - [:NEXT] -> (K1) return K1,K2\" % (k1,k2))\n",
    "\n",
    "for idx, row in dataframe.iterrows():\n",
    "    detail = row['detail']\n",
    "    if isinstance(detail,str) :\n",
    "        text = wordseg.cut(detail)\n",
    "        using_words = is_pre(text, row['name'])\n",
    "        using_words = set(using_words)\n",
    "        using_rel = [x for x in using_words if not has_rel(x,row['name'])]\n",
    "#         print('kn -> {} pre kn : {} cut txt : {}'.format(row['name'], is_pre(text, row['name']), text))\n",
    "        \n",
    "        for item in using_rel:\n",
    "#             print('kn -> {} next rel kn -> {}'.format(row['name'], item))\n",
    "            create_next_rel(row['name'], item)\n",
    "    \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 根据知识点成绩关联建立关系 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:25:55.433703Z",
     "start_time": "2020-03-19T07:25:55.026018Z"
    },
    "code_folding": [
     51,
     64
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K1': (0.093, 0.518), 'K2': (0.085, 0.528), 'K3': (0.068, 0.613), 'K4': (0.078, 0.633), 'K5': (0.09, 0.503), 'K6': (0.101, 0.523)}\n"
     ]
    }
   ],
   "source": [
    "# 1、https://blog.csdn.net/luanpeng825485697/article/details/79808669 生成样本数据\n",
    "# 2、https://blog.csdn.net/weixin_43060843/article/details/90269688?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task\n",
    "#    python faker 模拟数据\n",
    "# 3、https://cloud.tencent.com/developer/article/1576219 Python轻松实现统计学中重要的相关性分析\n",
    "# 4、https://blog.csdn.net/sinat_29957455/article/details/79007269 python pandas 相关性分析\n",
    "# 5、https://aic-fe.bnu.edu.cn/docs/20181205101832069569.pdf An Automatic Knowledge Graph Construction System forK-12 \n",
    "# 6、https://blog.csdn.net/Arwen_H/article/details/84938524 PCA 主成份分析\n",
    "# 7、https://www.jianshu.com/p/5c1cefd11477 中位数，百分位数\n",
    "# 8、https://blog.csdn.net/qq_36636519/article/details/86033415 Python之Pandas学习笔记(三) apply|applymap|map和grouppy\n",
    "# 9、https://blog.csdn.net/CSDNBigBoy/article/details/97034126 python 利用scipy.stats生成截断正态分布\n",
    "\n",
    "'''\n",
    "生成知识点成绩模拟数据\n",
    "知识点： \n",
    "模拟需检测知识点：平行四边形计算公式(K0)\n",
    "相关知识点：整数加法(K1)，整数减法(K2) --> 整数乘法(K3) --> 整数除法(K4)、常用的面积单位(K5)-->单位之间的换算(K6)、\n",
    "无关知识点：货币单位换算(K7)、质量常用换算(K8)、时间单位换算(K9)、鸡兔问题(K10)\n",
    "判断标准 P(Si -->Sj) AND P(^Sj --> ^Si)  : 关系为Sj为Si的前题，  P(Si -->Sj) 掌握了Si就等于掌握了Sj,  P(^Sj --> ^Si) : 没有掌握Sj就没有掌握Si\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.stats as stats\n",
    "\n",
    "K_MAP = {'K0':'平行四边形计算公式', 'K1':'整数加法', 'K2':'整数减法', 'K3':'整数乘法', 'K4':'整数除法','K5':'常用的面积单位',\n",
    "         'K6':'单位之间的换算','K7':'货币单位换算','K8':'质量常用换算','K9':'时间单位换算','K10':'鸡兔问题'}\n",
    "\n",
    "# 生成范围之内的正太分布数据\n",
    "def gen_k_performance(lower=60,uper=95, mu=80,sigma=10, size=1000):\n",
    "    x = stats.truncnorm(int((lower-mu)/sigma), int((uper-mu)/sigma), mu, sigma)\n",
    "    data = x.rvs(size)\n",
    "    data = data.astype(np.int)\n",
    "    return data\n",
    "\n",
    "# 生成模拟成绩数据\n",
    "def gen_all_data(size=1000):\n",
    "    data = {}\n",
    "    data['K1'] = gen_k_performance(size=size)\n",
    "    data['K2'] = gen_k_performance(size=size)\n",
    "    data['K3'] = ((data['K1'] + data['K2']) / 2).astype(np.int) + np.random.randint(-5,5,size)\n",
    "    data['K4'] = ((data['K1'] + data['K2']) / 2).astype(np.int) + np.random.randint(-5,5,size)\n",
    "    data['K5'] = gen_k_performance(size=size)\n",
    "    data['K6'] = data['K5'] + np.random.randint(-5,5,size)\n",
    "    data['K7'] = gen_k_performance(size=size)\n",
    "    data['K8'] = gen_k_performance(size=size)\n",
    "    data['K9']=  gen_k_performance(size=size)\n",
    "    data['K10'] = gen_k_performance(size=size)\n",
    "    data['K0'] = ((data['K3'] + data['K4'] + data['K6']) / 3).astype(np.int) +  np.random.randint(-5,5,size)\n",
    "    return data\n",
    "\n",
    "\n",
    "def coef_relation(k_data, km,kn):\n",
    "    '''\n",
    "    处理流程：\n",
    "    1、先计算协方差， 抽取关系系数较大的\n",
    "    2、两两分别计算影响度，找出关系\n",
    "    '''    \n",
    "    #    检测M是否是N的前置知识点\n",
    "    #     判断标准 P(Si -->Sj) AND P(^Sj --> ^Si)  : 关系为Sj为Si的前题，  P(Si -->Sj) 掌握了Si就等于掌握了Sj,  P(^Sj --> ^Si) : 没有掌握Sj就没有掌握Si\n",
    "    rel_forward_coef = len(np.where((k_data[kn]>=2) & (k_data[km] == 3) )[0]) / len(k_data) # P(Si -->Sj) 掌握了Si就等于掌握了Sj\n",
    "    rel_backward_coef = len(np.where((k_data[km]==1) & (k_data[kn] == 1) )[0]) / len(k_data) #  P(^Sj --> ^Si) : 没有掌握Sj就没有掌握Si\n",
    "    return rel_forward_coef, rel_backward_coef\n",
    "\n",
    "# 返回 k_name的前置知识点\n",
    "def get_relation(k_data,k_name,min_supp=0.05, min_coef=0.5):\n",
    "    rel_map = {}\n",
    "    for key in K_MAP.keys():\n",
    "        if k_name != key:\n",
    "            support, coef = coef_relation(k_data, key, k_name)\n",
    "            if support >= min_supp and coef >= min_coef:\n",
    "                rel_map['{}'.format(key)] = (support,coef)\n",
    "    return rel_map\n",
    "\n",
    "p_data  = gen_all_data(1000)\n",
    "p_data_values = np.array([x.tolist() for x in p_data.values()])\n",
    "p_data =  pd.DataFrame(p_data_values.T, columns=p_data.keys())\n",
    "percen = np.percentile(p_data,[60, 80, 100])\n",
    "pen_class = lambda x : 1 if x <= percen[0] else 2 if x > percen[0] and x <= percen[1] else 3  \n",
    "pen_class_data = p_data.applymap(pen_class)\n",
    "\n",
    "pen_class_data.to_csv('D:/PROJECT_TW/git/data/kg/k_performance.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:48:24.474639Z",
     "start_time": "2020-03-19T07:48:23.861511Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create next key 平行四边形计算公式->整数加法 weight 0.18058252427184465\n",
      "create next key 平行四边形计算公式->整数减法 weight 0.1650485436893204\n",
      "create next key 平行四边形计算公式->整数乘法 weight 0.13203883495145632\n",
      "create next key 平行四边形计算公式->整数除法 weight 0.15145631067961166\n",
      "create next key 平行四边形计算公式->常用的面积单位 weight 0.17475728155339804\n",
      "create next key 平行四边形计算公式->单位之间的换算 weight 0.19611650485436893\n",
      "create next key 整数乘法->整数加法 weight 0.3868421052631579\n",
      "create next key 整数乘法->整数减法 weight 0.3394736842105263\n",
      "create next key 整数乘法->整数除法 weight 0.27368421052631575\n",
      "create next key 整数除法->整数加法 weight 0.3341404358353511\n",
      "create next key 整数除法->整数减法 weight 0.31234866828087166\n",
      "create next key 常用的面积单位->单位之间的换算 weight 0.8113207547169811\n",
      "{'K0': {'K1': (0.093, 0.518), 'K2': (0.085, 0.528), 'K3': (0.068, 0.613), 'K4': (0.078, 0.633), 'K5': (0.09, 0.503), 'K6': (0.101, 0.523)}, 'K1': {'K3': (0.096, 0.51), 'K4': (0.097, 0.519)}, 'K2': {'K3': (0.105, 0.524), 'K4': (0.102, 0.533)}, 'K3': {'K1': (0.147, 0.51), 'K2': (0.129, 0.524), 'K4': (0.104, 0.601)}, 'K4': {'K0': (0.051, 0.633), 'K1': (0.138, 0.519), 'K2': (0.129, 0.533), 'K3': (0.095, 0.601)}, 'K5': {'K0': (0.05, 0.503), 'K6': (0.215, 0.536)}, 'K6': {'K5': (0.214, 0.536)}, 'K7': {}, 'K8': {}, 'K9': {}, 'K10': {}}\n"
     ]
    }
   ],
   "source": [
    "# 将前置知识点的权重更新到知识图谱\n",
    "from py2neo import Graph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "K_MAP = {'K0':'平行四边形计算公式', 'K1':'整数加法', 'K2':'整数减法', 'K3':'整数乘法', 'K4':'整数除法','K5':'常用的面积单位',\n",
    "         'K6':'单位之间的换算','K7':'货币单位换算','K8':'质量常用换算','K9':'时间单位换算','K10':'鸡兔问题'}\n",
    "# match (k1:Knowledge)-[r:NEXT]->(k2:Knowledge) where r.weight>=0 return k1,r,k2 查询\n",
    "# match (:Knowledge)-[r:NEXT]->(:Knowledge) where r.weight>=0 delete r 清除关系\n",
    "pen_class_data = pd.read_csv('D:/PROJECT_TW/git/data/kg/k_performance.csv')\n",
    "k_rel = {}\n",
    "for ik in K_MAP.keys():\n",
    "    # 合并MAP, 比较MAP，创建关系\n",
    "    k_rel.update({ik: get_relation(pen_class_data, ik, min_supp=0.05, min_coef=0.5)})\n",
    "\n",
    "\n",
    "\n",
    "graph = Graph(uri='bolt://127.0.0.1:7687',auth=('neo4j','654321')) \n",
    "# 检测两个知识点是否有关系\n",
    "def has_next_rel(k1, k2):\n",
    "    result = False\n",
    "    rdata = graph.run(\"MATCH (K:Knowledge {name:'%s'}) - [r] -> (P:Knowledge {name:'%s'}) RETURN r\" % (k1,k2)).data()\n",
    "    if (len(rdata) > 0):\n",
    "        result = True\n",
    "    return result\n",
    "\n",
    "# 创建知识点NEXT关系 ， k2 -> NEXT --> k1, K1需要先掌握K2知识点\n",
    "def create_next_rel(k1,k2,weight):\n",
    "    print('create next key {}->{} weight {}'.format(k1,k2,weight))\n",
    "    graph.run(\"MATCH (K1:Knowledge {name:'%s'}), (K2:Knowledge {name:'%s'}) CREATE (K2) - [:NEXT {weight:%s}] -> (K1) return K1,K2\" % (k1,k2,weight))\n",
    "\n",
    "# 查询关系 MATCH (K1:Knowledge {name:'平行四边形计算公式'})-[relN:NEXT]- (K2:Knowledge {name:'整数加法'}) return K1,K2,relN\n",
    "def query_next_rel(k1,k2):\n",
    "    graph.run(\"MATCH (K1:Knowledge {name:'%s'}) -[relNext:NEXT]- (K2:Knowledge {name:'%s'})  return K1,K2\" % (k1,k2,relNext))\n",
    "    \n",
    "for m_key in k_rel.keys():\n",
    "    if len(k_rel[m_key].keys()) > 0:\n",
    "        p_sum_value = sum(np.array(list(k_rel[m_key].values()))[:,0])\n",
    "        n_sum_value = sum(np.array(list(k_rel[m_key].values()))[:,1])\n",
    "#         print(m_key, ':', p_sum_value,':', n_sum_value)\n",
    "        for p_key in k_rel[m_key].keys():\n",
    "            #             print(K_MAP[p_key], '-->', K_MAP[m_key], ' has next rel :',has_next_rel(K_MAP[p_key],K_MAP[m_key]) )\n",
    "            #    比较K相关性值\n",
    "            p_value = k_rel[m_key][p_key][0]\n",
    "            if m_key in k_rel[p_key] and p_value < k_rel[p_key][m_key][0]:\n",
    "                continue\n",
    "#             print(K_MAP[p_key], '-->', K_MAP[m_key], ' has next rel :',has_next_rel(K_MAP[p_key],K_MAP[m_key]))\n",
    "            create_next_rel(K_MAP[m_key], K_MAP[p_key], p_value/p_sum_value) \n",
    "                \n",
    "            \n",
    "print(k_rel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T02:01:41.136572Z",
     "start_time": "2020-03-16T02:01:41.128575Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.146, 0.133, 0.101, 0.124])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 从非结构化数据中提取关系、实体 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 图谱扩展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 增加资源节点 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 文档、PPT、视频之类 已结构化的数据， 无结构化的资源？？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 增加习题节点 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 已结构化的数据， 无结构化的资源？？？？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "339.85px",
    "left": "996px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
