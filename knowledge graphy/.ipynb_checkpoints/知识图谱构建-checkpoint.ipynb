{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据源"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://wenku.baidu.com/view/c9f4e5e67f1922791788e82a.html\n",
    "https://wenku.baidu.com/view/dd6b730c76c66137ee06199e.html\n",
    "https://wenku.baidu.com/view/328ffe89195f312b3169a5f7.html\n",
    "https://www.sohu.com/a/324251797_818374 !!!!\n",
    "https://wenku.baidu.com/view/c9f4e5e67f1922791788e82a.html ！！！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关技术"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " 对文本进行处理，提取关键词，包括分词技术等，知识图谱基础技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "整理好的 ” 小学生数据知识点.txt\" 基本为半结构化数据， 知识点基本以”：“隔开 前部分是知识点，后部分是内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图谱构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 知识抽取"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "实体结构：\n",
    "  实体名， 属性：（内容描述， 归类）\n",
    "处理流程：\n",
    "一、提取专家半结构化数据进行知识点实体抽取\n",
    "1、 按层级及相对结构化文本的特点提取所有知识点\n",
    "2、 知识点归类、合并， （暂时合并不需要，合并主要针对两个实体代表同一实体的情况下）。归类暂时先通过导级关系进行归类，根据实际情况再通过SVM类似的方法进行处理。\n",
    "二、扩展方式\n",
    "1、实体通过百度百科类似的搜索引擎查找方式进行扩展。  （略）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n注意生成的csv文件需保存到 neo4j 应用目录import 下\\n执行脚本：\\nLOAD CSV WITH HEADERS FROM \"file:/math.csv\" AS row\\nCREATE (n:Knowledge)\\nset n=row;\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "file_name = 'D:\\\\PROJECT_TW\\\\twedu\\\\解决方案\\\\小学数学知识点.txt'\n",
    "out_file_name = 'D:\\\\PROJECT_TW\\\\twedu\\\\解决方案\\\\小学数学知识点.csv'\n",
    "dict_file_name = \"D:\\\\PROJECT_TW\\\\twedu\\\\解决方案\\\\小学数学知识点字典.txt\"\n",
    "pattern = r'[:|：]' \n",
    "\n",
    "# 得到当前层级数\n",
    "def get_level(line):\n",
    "    ret_level = -1\n",
    "    lev = {\n",
    "        1 : r'第[一|二|三|四|五|六]章',\n",
    "        2 : r'[一|二|三|四|五|六|七|八|九]、',\n",
    "        3 : r'（[一|二|三|四|五|六]）',\n",
    "        4 : r'\\d+、',\n",
    "        5 : r'[⑴|⑵|⑶|⑷|⑸|⑹|⑺|⑻]'}\n",
    "    for key in lev.keys():\n",
    "        if re.match(lev[key],line):\n",
    "            break\n",
    "            \n",
    "    if key:\n",
    "        ret_level = key\n",
    "    return ret_level, lev\n",
    "details = []\n",
    "\n",
    "with open(file_name,'r',encoding='utf-8') as f:\n",
    "    current_lev_map = {}\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n').strip()\n",
    "        if len(line) > 0:\n",
    "            result = re.split(pattern, line, maxsplit=1)\n",
    "            level,lev_define = get_level(line)\n",
    "            result = [x.strip('\\n') for x in result]\n",
    "#             print('level --> ',level, ' result --> ', result[0])\n",
    "            result[0] = re.split(lev_define[level],result[0],maxsplit=1)[1]\n",
    "            current_lev_map[level] = result[0]\n",
    "            up_title = ''\n",
    "            if level >= 2:\n",
    "                up_title = current_lev_map[level-1]\n",
    "            details.append([up_title.strip(), result[0].strip(), result[1].strip() if len(result) > 1 else '' ])\n",
    "#             print('title:{}-->{}'.format(up_title, result))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataframe = pd.DataFrame(np.array(details),columns=['title','name','detail'])\n",
    "dataframe.to_csv(out_file_name,index=False,sep=',',encoding='utf_8_sig')\n",
    "\n",
    "with open(dict_file_name, 'w', encoding='utf-8') as f:\n",
    "    content = dataframe.name.values.tolist()\n",
    "    content.append('圆点')\n",
    "    text = '\\n'.join(content)\n",
    "    f.writelines(text)\n",
    "        \n",
    "print('over !')\n",
    "\n",
    "'''\n",
    "清除所有数据\n",
    "MATCH (n)\n",
    "OPTIONAL MATCH (n)-[r]-()\n",
    "DELETE n,r\n",
    "\n",
    "注意生成的csv文件需保存到 neo4j 应用目录import 下\n",
    "执行脚本：\n",
    "LOAD CSV WITH HEADERS FROM \"file:/math.csv\" AS row\n",
    "CREATE (n:Knowledge)\n",
    "set n=row;\n",
    "'''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关系抽取 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "关系说明：\n",
    "    关系现各类分为： 属于， 前提（即该知识点需要掌握的其它知识点）  \n",
    "处理流程：\n",
    "一、根据提取的专家半结构化数据的数据进行关系抽取\n",
    "1、 按文本中的层级抽取”属于“关系， 注意需关闭某些”概念“这样一类的层级\n",
    "\n",
    "2、 ”前提\"关系的抽取从知识点描述中提取，检测其内容中是否包含其它知识点.  \n",
    "\n",
    "Chaplot  andKoedinger  use  educational  data  to  induce  the  prerequisiterelations among multiple units in a course [2], and Liang et al.recovers prerequisite relations from course dependencies [4].Another group of researchers utilize the observed relationsamong courses to create a directed universal concept graph.  In addition,  we utilize students’performance data rather than course descriptions to identifyrelations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 简单关系抽取（根据知识点文本内容抽取NEXT关系）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "1、根据文档结构建立PARTOF关系\n",
    "执行脚本：\n",
    "MATCH (a:Knowledge), (b:Knowledge) \n",
    "   WHERE a.name = b.title\n",
    "CREATE (a)-[:INCLUDE]->(b) \n",
    "RETURN a,b \n",
    "\n",
    "2、根据CSV知识点内容中检索方式，建立USE关系\n",
    "处理流程（极简流程）：\n",
    "1） 对内容分词，然后通过分词去匹配， 注意（这里关系有可能是引用和使用两种，怎么样进行区分？？？）  分词工具包： https://github.com/lancopku/pkuseg-python\n",
    "'''\n",
    "import pandas as pd\n",
    "import pkuseg\n",
    "import numpy as np\n",
    "from py2neo import Graph\n",
    "dict_file_name = \"D:\\\\PROJECT_TW\\\\twedu\\\\解决方案\\\\小学数学知识点字典.txt\"\n",
    "file_name = 'D:\\\\PROJECT_TW\\\\twedu\\\\解决方案\\\\小学数学知识点.csv'\n",
    "wordseg = pkuseg.pkuseg(user_dict=dict_file_name)\n",
    "dataframe = pd.read_csv(file_name)\n",
    "graph = Graph(uri='bolt://127.0.0.1:7687',auth=('neo4j','654321')) \n",
    "\n",
    "kn_dict = None\n",
    "with open(dict_file_name,'r',encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    kn_dict = [x.strip() for x in lines]\n",
    "kn_dict.remove('圆点')\n",
    "# print(kn_dict)\n",
    "# 检测前置情况, 检测 cut text 是否在包含filter name\n",
    "def is_pre(cut_text,filter_name):\n",
    "    pre_kn = []\n",
    "    cut_text = np.array(cut_text)\n",
    "    for item in kn_dict:\n",
    "        result = np.where(cut_text==item)\n",
    "        if len(result[0]) > 0 and item != filter_name:\n",
    "            pre_kn.append(item)\n",
    "    return pre_kn\n",
    "\n",
    "# 检测两个知识点是否有关系\n",
    "def has_rel(k1, k2):\n",
    "    result = False\n",
    "    rdata = graph.run(\"MATCH (K:Knowledge {name:'%s'}) - [r] -> (P:Knowledge {name:'%s'}) RETURN r\" % (k1,k2)).data()\n",
    "    if (len(rdata) > 0):\n",
    "        result = True\n",
    "    return result\n",
    "\n",
    "# 创建知识点NEXT关系 ， k2 -> NEXT --> k1, K1需要先掌握K2知识点\n",
    "def create_next_rel(k1,k2):\n",
    "    graph.run(\"MATCH (K1:Knowledge {name:'%s'}), (K2:Knowledge {name:'%s'}) CREATE (K2) - [:NEXT] -> (K1) return K1,K2\" % (k1,k2))\n",
    "\n",
    "for idx, row in dataframe.iterrows():\n",
    "    detail = row['detail']\n",
    "    if isinstance(detail,str) :\n",
    "        text = wordseg.cut(detail)\n",
    "        using_words = is_pre(text, row['name'])\n",
    "        using_words = set(using_words)\n",
    "        using_rel = [x for x in using_words if not has_rel(x,row['name'])]\n",
    "#         print('kn -> {} pre kn : {} cut txt : {}'.format(row['name'], is_pre(text, row['name']), text))\n",
    "        \n",
    "        for item in using_rel:\n",
    "#             print('kn -> {} next rel kn -> {}'.format(row['name'], item))\n",
    "            create_next_rel(row['name'], item)\n",
    "    \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据知识点成绩关联建立关系 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          四边        加法        减法        乘法        除法        面积        换算        货币        质量        时间        鸡兔\n",
      "四边  1.000000  0.603799  0.620431  0.856930  0.856930  0.551827  0.551827  0.110345 -0.023628 -0.051363  0.053145\n",
      "加法  0.603799  1.000000  0.020375  0.716635  0.716635  0.010857  0.010857  0.004721  0.032711 -0.038878 -0.113238\n",
      "减法  0.620431  0.020375  1.000000  0.711905  0.711905  0.050748  0.050748  0.103199 -0.039354 -0.096052  0.075313\n",
      "乘法  0.856930  0.716635  0.711905  1.000000  1.000000  0.043027  0.043027  0.075307 -0.004476 -0.094314 -0.027003\n",
      "除法  0.856930  0.716635  0.711905  1.000000  1.000000  0.043027  0.043027  0.075307 -0.004476 -0.094314 -0.027003\n",
      "面积  0.551827  0.010857  0.050748  0.043027  0.043027  1.000000  1.000000  0.092039 -0.038556  0.053040  0.146703\n",
      "换算  0.551827  0.010857  0.050748  0.043027  0.043027  1.000000  1.000000  0.092039 -0.038556  0.053040  0.146703\n",
      "货币  0.110345  0.004721  0.103199  0.075307  0.075307  0.092039  0.092039  1.000000  0.002507 -0.148560  0.054032\n",
      "质量 -0.023628  0.032711 -0.039354 -0.004476 -0.004476 -0.038556 -0.038556  0.002507  1.000000 -0.017379 -0.134363\n",
      "时间 -0.051363 -0.038878 -0.096052 -0.094314 -0.094314  0.053040  0.053040 -0.148560 -0.017379  1.000000 -0.203843\n",
      "鸡兔  0.053145 -0.113238  0.075313 -0.027003 -0.027003  0.146703  0.146703  0.054032 -0.134363 -0.203843  1.000000\n"
     ]
    }
   ],
   "source": [
    "# 1、https://blog.csdn.net/luanpeng825485697/article/details/79808669 生成样本数据\n",
    "# 2、https://blog.csdn.net/weixin_43060843/article/details/90269688?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task\n",
    "#    python faker 模拟数据\n",
    "# 3、https://cloud.tencent.com/developer/article/1576219 Python轻松实现统计学中重要的相关性分析\n",
    "# 4、https://blog.csdn.net/sinat_29957455/article/details/79007269 python pandas 相关性分析\n",
    "# 5、https://aic-fe.bnu.edu.cn/docs/20181205101832069569.pdf An Automatic Knowledge Graph Construction System forK-12 Education\n",
    "'''\n",
    "生成知识点成绩模拟数据\n",
    "知识点： \n",
    "模拟需检测知识点：平行四边形计算公式(K0)\n",
    "相关知识点：整数加法(K1)，整数减法(K2) --> 整数乘法(K3) --> 整数除法(K4)、常用的面积单位(K5)-->单位之间的换算(K6)、\n",
    "无关知识点：货币单位换算(K7)、质量常用换算(K8)、时间单位换算(K9)、鸡兔问题(K10)\n",
    "\n",
    "判断标准 P(Si -->Sj) AND P(^Sj --> ^Si)  : 关系为Sj为Si的前题，  P(Si -->Sj) 掌握了Si就等于掌握了Sj,  P(^Sj --> ^Si) : 没有掌握Sj就没有掌握Si\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "K1 = np.round(np.random.normal(90,5, 100),0)\n",
    "K2 = np.round(np.random.normal(90,5, 100),0)\n",
    "K3 = (K1 + K2) / 2\n",
    "K4 = (K1 + K2) / 2\n",
    "K5 = np.round(np.random.normal(90,5, 100),0)\n",
    "K6 = K5 - 2\n",
    "K7 = np.round(np.random.normal(90,5, 100),0)\n",
    "K8 = np.round(np.random.normal(90,5, 100),0)\n",
    "K9 = np.round(np.random.normal(90,5, 100),0)\n",
    "K10 = np.round(np.random.normal(90,5, 100),0)\n",
    "K0 = (K3 + K4 + K6) / 3\n",
    "\n",
    "K = np.array([K0,K1,K2,K3,K4,K5,K6,K7,K8,K9,K10])\n",
    "KP = pd.DataFrame(K.T, columns=['K0','K1','K2','K3','K4','K5','K6','K7','K8','K9','K10'])\n",
    "print(KP.corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "??KP.cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 图谱扩展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 增加资源节点 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 增加习题节点 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
