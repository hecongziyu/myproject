{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) http://educationaldatamining.org/files/conferences/EDM2018/papers/EDM2018_paper_139.pdf  采用红黑树的思想，结合BKT减少学习时间\n",
    "\n",
    "2) https://www.researchgate.net/publication/220807585_Estimating_programming_knowledge_with_Bayesian_knowledge_tracing?_sg=LTDqpx9gm8Cz5OXfgjBfZQKuytPQJdh83M9h43tGZiFZKxnWotrND4fCdry9v4dPvpLJCuYmYcOKTAkEuZFQdlHjI9A49c6n1ucWIMUUoebu6Q\n",
    "\n",
    "3) https://www.semanticscholar.org/paper/Finding-Similar-Exercises-in-Online-Education-Liu-Huang/41c828743f69c0ec53f59c42704f427ac879613b\n",
    "\n",
    "4) https://www.semanticscholar.org/paper/Knowledge-tracing-with-an-intelligent-agent%2C-in-an-Trifa-Sba%C3%AF/fda25ab608702fcdb8ce1f259d55a7ab576e15b0\n",
    "\n",
    "5) http://www.educationaldatamining.org/EDM2017/proc_files/papers/paper_72.pdf  通过Markov Chains预测用户下一个行为，改用LSTM更为方便，需要大量历史数据进行训练。\n",
    "\n",
    "6) https://arxiv.org/pdf/1811.03388.pdf  Factorization Machines for Knowledge Tracing , 可用于评估学生能力  P(x) = 能力 - 试题难度. 开源软件 -->  KMT, pywFM\n",
    "\n",
    "7) https://www.docin.com/p-764417569.html?docfrom=rrela 基于贝叶斯网络的NBA比分预测和球员能力评估模型, 包括了模型的算法一些总结\n",
    "\n",
    "8) http://www.columbia.edu/~rsb2162/paper_143.pdf  BTK 训练好的参数的应用\n",
    "\n",
    "9）https://www2.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-98.pdf\n",
    "\n",
    "10) doc: 397-Article Text-1853-1-10-20190624.pdf\n",
    "\n",
    "11） https://blog.csdn.net/tanzhangwen/article/details/8262017  动态贝叶斯网络DBN\n",
    "\n",
    "12) https://arxiv.org/pdf/1806.02180.pdf  Addressing Two Problems in Deep Knowledge Tracing viaPrediction-Consistent Regularization\n",
    "\n",
    "13) doc:  https://www.cs.cmu.edu/~zhitingh/data/lats16structured.pdf  Structured Knowledge Tracing Models for Student Assessment on Coursera\n",
    "\n",
    "14) https://www.freecodecamp.org/news/adaptive-learning-systems/ How to build an adaptive learning system\n",
    "\n",
    "15) http://pact.cs.cmu.edu/pubs/New%20potentials%20for%20ITS-source.pdf  1New Potentials for Data-Driven Intelligent Tutoring System Development and Optimization \n",
    "\n",
    "16) https://crowston.syr.edu/sites/crowston.syr.edu/files/training%20v3%20to%20share_0.pdf\n",
    "\n",
    "17) https://www.zhihu.com/question/60893517 如何理解odds即p/(1-p)在数据预处理中的应用？odds即赔率，是一个0到正无穷的实数值，相比于 [0, 1] 的概率值具有更大的范围。同时，赔率理解起来更直观，假设中国队世界杯夺冠的概率为 p = 0.01，大多数人对概率没有直观感觉。但如果换成赔率为 1/99，其所表达的意思为如果赌博中国队世界杯夺冠100次，会输掉99次。\n",
    "\n",
    "作者：赵熙\n",
    "链接：https://www.zhihu.com/question/60893517/answer/183083929\n",
    "来源：知乎\n",
    "著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n",
    "\n",
    "红黑树\n",
    "\n",
    "bing : Intelligent Scheduler student study Schedules\n",
    "bing : bayesian knowledge tracing how to evaluate learning materials   transform\n",
    "bing : ITS how to evaluate learning materials transform\n",
    "\n",
    "P(L0): 预计掌握情况（可通过预测试方式得到）\n",
    "P(Ln): 通过后的掌握情况\n",
    "P(T):  转换情况\n",
    "P(G), P(S): 根据题型来选择\n",
    "\n",
    "1、知识点测试结果, 数据格式说明：\n",
    "    student 1: {q0, a0}, {q1, a1}, {q2, a2} ... {qn, an}  -->  q0  试题编号（后期可扩展到基本内容等方面）\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# data_path = './data/train_data.npy'\n",
    "# train_data = np.load(data_path, allow_pickle=True)\n",
    "# # fast-correct, fast-incorrect, slow-correct, slow-incorrect\n",
    "# train_feature = [[0,1,2,3]]\n",
    "np.random.seed(1) \n",
    "gen_number = 1000\n",
    "exam_number = 10\n",
    "feature = [0,1]  # 0: Correct, 1: incorrect\n",
    "train_data = []\n",
    "for _ in range(gen_number):\n",
    "    x = []\n",
    "    for idx in range(exam_number):\n",
    "        if np.random.randint(10) > 7:\n",
    "            x.append('1')\n",
    "        else:\n",
    "            x.append('0')\n",
    "    train_data.append(x)\n",
    "\n",
    "# print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTK实现 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     205
    ]
   },
   "outputs": [],
   "source": [
    "# hmm.py\n",
    "import math\n",
    "import numpy\n",
    "from numpy import random as rand\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from functools import reduce\n",
    "class hmm:\n",
    "    def __init__(self, n_state, obs_symbols, **args):\n",
    "        \"\"\"\n",
    "        Keywords\n",
    "        :param n_states (int): number of hidden states\n",
    "        :param output (list, for example[\"0\",\"1\"]): the output symbol notations\n",
    "        :param mode (string. For example, performance, time, performance+time): the output mode\n",
    "        :param args: 'Pi' - matrix of initial state probability distribution\n",
    "                     'T' - matrix of transmission probability\n",
    "                     'E' - matrix of emission probability\n",
    "                     'F' - fixed emission probability for the given state {'state1': [0.2, 0.8]}\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # Number of hidden states\n",
    "        self.N = n_state\n",
    "        # Observation symbols for each type of observation\n",
    "        # For example, {correct, incorrect} and {fast, slow}\n",
    "        self.V = obs_symbols\n",
    "        # Number of observation symbols for each type\n",
    "        # For example, [2, 5]\n",
    "        self.M = list(map(len, obs_symbols))\n",
    "#         print('self M --> {}'.format(self.M))\n",
    "        # Number of observation types\n",
    "        self.n_elements = len(self.V)\n",
    "        # The mapping of symbols to numbers\n",
    "        self.symbol_map = []\n",
    "        # Number of observation types\n",
    "        for i in range(self.n_elements):\n",
    "            self.symbol_map.append(dict(zip(self.V[i], range(len(self.V[i])))))\n",
    "\n",
    "        # Initialize transmission probability matrix\n",
    "        if 'T' in args:\n",
    "            self.T = args['T']\n",
    "            if numpy.shape(self.T) != (self.N, self.N):\n",
    "                raise ValueError(\"The transmission probability matrix dimension mismatches the given states number.\")\n",
    "\n",
    "            if not numpy.array_equal(self.T.sum(1), numpy.array([1.0] * len(self.T.sum(1)))):\n",
    "                raise ValueError(\"The sum of each row in the transmission matrix should equal to 1\")\n",
    "        else:\n",
    "            raw_T = rand.uniform(0, 1, self.N * self.N).reshape(self.N, self.N)\n",
    "            raw_T_sum = raw_T.sum(axis=1, keepdims=True)\n",
    "            self.T = raw_T.astype(float) / raw_T_sum\n",
    "\n",
    "        self.E = []\n",
    "\n",
    "        # Initialize emission probability matrix\n",
    "        if 'E' in args:\n",
    "            self.E = args['E']\n",
    "\n",
    "            if len(self.E) != self.n_elements:\n",
    "                raise ValueError(\"There are \" + str(self.n_elements) + \" in the observations.\")\n",
    "\n",
    "            for i in range(self.n_elements):\n",
    "                if numpy.shape(self.E[i]) != (self.N, self.M[i]):\n",
    "                    raise ValueError(\"The emission probability matrix dimension mismatches the given states number and \"\n",
    "                                     \"output symbols number\")\n",
    "\n",
    "                if not numpy.allclose(self.E[i].sum(1), numpy.array([1] * len(self.E[i].sum(1)))):\n",
    "                    raise ValueError(\"The sum of each row in the emission probability matrix should equal to 1\")\n",
    "        else:\n",
    "            for i in range(self.n_elements):\n",
    "                raw_E = rand.uniform(0, 1, self.N * self.M[i]).reshape(self.N, self.M[i])\n",
    "                raw_E_sum = raw_E.sum(axis=1, keepdims=True)\n",
    "                self.E.append(raw_E.astype(float) / raw_E_sum)\n",
    "\n",
    "        # Initialize the initial probability\n",
    "        if 'Pi' in args:\n",
    "            self.Pi = args['Pi']\n",
    "\n",
    "            if len(self.Pi) != self.N:\n",
    "                raise ValueError(\"The initial state probability dimension mismatches the given states number.\")\n",
    "\n",
    "            if self.Pi.sum() != 1:\n",
    "                raise ValueError(\"The initial state probability does not add up to 1.\")\n",
    "\n",
    "        else:\n",
    "            raw_Pi = numpy.array([1] * self.N)\n",
    "            self.Pi = raw_Pi.astype(float) / raw_Pi.sum()\n",
    "\n",
    "        self._print_HMM(\"HMM Initialization\")\n",
    "\n",
    "    def _print_HMM(self, label, write_to_file=False):\n",
    "        \"\"\"\n",
    "        Keywords\n",
    "        :param label (String \"The initialized HMM parameters\")\n",
    "        :param write_to_file (boolean): whether to print out to file or not\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        results = \"\\n\" * 2 + \"*\" * 24 + \"\\n\" + label + \"\\n\" + \"*\" * 24 + \"\\n\" \\\n",
    "                  + \"\\n1) Numerber of hidden states:\" + str(self.N) \\\n",
    "                  + \"\\n2) Number of observable symbols:\" + str(self.V) \\\n",
    "                  + \"\\n3) The symbol mapping in HMM:\" + str(self.symbol_map) \\\n",
    "                  + \"\\n4) The transmission proability matrix T:\\n\" + str(self.T) \\\n",
    "                  + \"\\n5) The emission probability matrix E:\\n\" + str(self.E) \\\n",
    "                  + \"\\n6) The initial state probability Pi: \\n\" + str(self.Pi) + \"\\n\"\n",
    "        print(results)\n",
    "        \n",
    "    \n",
    "    def obs_index(self, Obs, Obs_type):\n",
    "        \"\"\"\n",
    "        Convert the observation sequences into sequence using symbols \"0\", \"1\" or \"2\"\n",
    "        :param Obs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        obs_index_seq = []\n",
    "\n",
    "        for o in Obs:\n",
    "            if o not in self.symbol_map[Obs_type]:\n",
    "                raise ValueError(\"The observation symbol \\\"\" + o + \"\\\" is not defined in HMM\")\n",
    "            obs_index_seq.append(self.symbol_map[Obs_type][o])\n",
    "\n",
    "        return obs_index_seq\n",
    "\n",
    "    def forward(self, Obs, scaling=True, debug=False):\n",
    "        \"\"\"\n",
    "        Calculate the probability of an observation sequence given the model parameters\n",
    "        P(Obs|hmm)\n",
    "\n",
    "        Alpha is defined as P(O_1:T,S_T|hmm)\n",
    "\n",
    "        :param Obs: List. Observation sequence\n",
    "        :param scaling: boolean. Scale the Alpha matrix to let the column sums to 1\n",
    "        :param debug: boolean. Whether to print output of each step\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if debug:\n",
    "            print(\"\\n\" * 2 + \"*\" * 23 + \"\\n\" + \"*\" * 2 + \n",
    "                  \" FORWARD ALGORITHM \" + \"*\" * 2 + \"\\n\" + \"*\" * 23 + \"\\n\")\n",
    "            \n",
    "        observation = []\n",
    "        # The observation sequence using observation symbol notations. It is a list [\"1\",\"1\",\"0\",\"1\"]\n",
    "\n",
    "        for i in range(self.n_elements):\n",
    "            observation.append(self.obs_index(Obs, i))\n",
    "\n",
    "        T = len(observation[0])\n",
    "        # create scaling vector\n",
    "        if scaling:\n",
    "            c = numpy.zeros([T], float)\n",
    "\n",
    "        # Initialization\n",
    "        Alpha=numpy.zeros([self.N, T], float)\n",
    "        Alpha[:, 0] = self.Pi\n",
    "        #  \n",
    "        for i in range(self.n_elements):\n",
    "            Alpha[:, 0] *= self.E[i][:, int(observation[i][0])]\n",
    "\n",
    "        if scaling:\n",
    "            c[0] = 1 / Alpha[:, 0].sum()\n",
    "            Alpha[:, 0] = Alpha[:, 0] * c[0]\n",
    "\n",
    "        if debug:\n",
    "            print(\"t=0\")\n",
    "            print(Alpha[:, 0])\n",
    "\n",
    "        # Induction\n",
    "        for t in range(1, T):\n",
    "            #  P(Ln) = P(Ln-1) * self.T  学习状态的变化（如从不会到会，从会到不会的概率）\n",
    "            Alpha[:, t] = numpy.dot(Alpha[:, t - 1], self.T)\n",
    "            for i in range(self.n_elements):\n",
    "                #  E STEP， 根据观测值得到隐藏状态的期待值\n",
    "                Alpha[:, t] *= self.E[i][:, int(observation[i][t])]\n",
    "\n",
    "            if scaling:\n",
    "                c[t] = 1 / Alpha[:, t].sum()\n",
    "                Alpha[:, t] = Alpha[:, t] * c[t]\n",
    "\n",
    "            if debug:\n",
    "                print(\"t=\" + str(t))\n",
    "                print(Alpha[:, t])\n",
    "\n",
    "        # Termination\n",
    "        if scaling:\n",
    "            log_prob = - reduce((lambda x, y: x + y), numpy.log(c[:T]))\n",
    "            if debug:\n",
    "                print(\"\\nAlpha:\")\n",
    "                print(Alpha)\n",
    "                print(\"\\nc:\")\n",
    "                print(c)\n",
    "                print(\"\\nP(Obs|hmm)=\" + str(log_prob))\n",
    "                # print \"c[T-1]: \" + str(c[T-1])\n",
    "            return (log_prob, Alpha, c)\n",
    "\n",
    "        else:\n",
    "\n",
    "            log_prob = numpy.log(numpy.sum(Alpha[:, T - 1]))\n",
    "\n",
    "            if debug:\n",
    "                print(\"\\nAlpha:\")\n",
    "                print(Alpha)\n",
    "                c =(1.0 / Alpha.sum(0))\n",
    "                print(c)\n",
    "                print(\"\\nP(Obs|hmm)=\" + str(log_prob))\n",
    "\n",
    "            return (log_prob, Alpha)\n",
    "\n",
    "    def backward(self, Obs, scaling, debug=False, **args):\n",
    "        \"\"\"\n",
    "        Calculate the probability of a partial observation sequence from t+1 to T given the model params.\n",
    "        Beta is defined as P(O_1:T|S_T, hmm)\n",
    "        :param Obs: Observation sequence\n",
    "        :return: Beta\n",
    "        \"\"\"\n",
    "        if debug:\n",
    "            print(\"\\n\" * 2 + \"*\" * 24 + \"\\n\" + \"*\" * 2 + \" BACKWARD ALGORITHM \" + \"*\" * 2 + \"\\n\" + \"*\" * 24 + \"\\n\")\n",
    "\n",
    "        observation = []\n",
    "        # The observation sequence using observation symbol notations. It is a list [\"1\",\"1\",\"0\",\"1\"]\n",
    "        for i in range(self.n_elements):\n",
    "            observation.append(self.obs_index([each[i] for each in Obs], i))\n",
    "\n",
    "        T = len(observation[0])\n",
    "\n",
    "        if scaling:\n",
    "            c = numpy.zeros([T], float)\n",
    "        # Initialization\n",
    "        Beta = numpy.zeros([self.N, T], float)\n",
    "        Beta[:, T - 1] = 1\n",
    "        if scaling:\n",
    "            c[T - 1] = 1 / Beta[:, T - 1].sum()\n",
    "            Beta[:, T - 1] = Beta[:, T - 1] * c[T - 1]\n",
    "        if debug:\n",
    "            print(\"t=\" + str(T - 1))\n",
    "            print(Beta[:, T - 1])\n",
    "\n",
    "        # Induction\n",
    "\n",
    "        for t in reversed(range(T - 1)):\n",
    "            temp = self.T.copy()\n",
    "            for i in range(self.n_elements):\n",
    "                temp *= self.E[i][:, int(observation[i][t + 1])]\n",
    "\n",
    "            Beta[:, t] = numpy.dot(temp, Beta[:, t + 1])\n",
    "            if scaling:\n",
    "                c[t] = 1 / Beta[:, t].sum()\n",
    "                Beta[:, t] = Beta[:, t] * c[t]\n",
    "\n",
    "            if debug:\n",
    "                print(\"t=\" + str(t))\n",
    "                print(Beta[:, t])\n",
    "\n",
    "        # if 'c' in args:\n",
    "        #    Beta = Beta * args['c']\n",
    "\n",
    "        if scaling:\n",
    "\n",
    "            if debug:\n",
    "                print(\"\\nBeta:\")\n",
    "                print(Beta)\n",
    "\n",
    "            return Beta\n",
    "        else:\n",
    "            if debug:\n",
    "                print(\"\\nBeta:\")\n",
    "                print(Beta)\n",
    "            return Beta\n",
    "\n",
    "    def baum_welch(self, Obs_seq, **args):\n",
    "        \"\"\"\n",
    "        Adjust the model parameters to maximize the probability of the observation sequence given the model\n",
    "\n",
    "        Define:\n",
    "\n",
    "        Gamma_t(i) = P(O_1:T, q_t = S_i | hmm) as the probability of in state i at time t and having the\n",
    "        observation sequence.\n",
    "\n",
    "        Xi_t(i,j) = P(O_1:T, q_t-1 = S_i, q_t = S_j | hmm) as the probability of transiting from state i\n",
    "        to state j and having the observation sequence.\n",
    "\n",
    "\n",
    "        :param Obs_seq: A set of observation sequence\n",
    "        :param args:\n",
    "            epochs: number of iterations to perform EM, default is 20\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # print \"\\n\"*2+ \"*\"*24 + \"\\n\" +\"*\"*1+\" Bawn Welch ALGORITHM \"+\"*\"*1 + \"\\n\" + \"*\"*24 + \"\\n\"\n",
    "        epochs = args['epochs'] if 'epochs' in args else 100\n",
    "\n",
    "        updatePi = args['updatePi'] if 'updatePi' in args else True\n",
    "        updateT = args['updateT'] if 'updateT' in args else True\n",
    "        updateE = args['updateE'] if 'updateE' in args else True\n",
    "        debug = args['debug'] if 'debug' in args else False\n",
    "        epsilon = args['epsilon'] if 'epsilon' in args else 0.001\n",
    "\n",
    "        LLS = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch \" + str(epoch))\n",
    "\n",
    "            # Expected number of probability of starting from Si\n",
    "            exp_si_t0 = numpy.zeros([self.N], float)\n",
    "            # Expected number of transition from Si\n",
    "            exp_num_from_Si = numpy.zeros([self.N], float)\n",
    "            # Expected number of being in Si\n",
    "            exp_num_in_Si = numpy.zeros([self.N], float)\n",
    "            # Expected number of transition from Si to Sj\n",
    "            exp_num_Si_Sj = numpy.zeros([self.N * self.N], float).reshape(self.N, self.N)\n",
    "            # Expected number of in Si observing symbol Vk\n",
    "            exp_num_in_Si_Vk = []\n",
    "            for i in range(self.n_elements):\n",
    "                exp_num_in_Si_Vk.append(numpy.zeros([self.N, self.M[i]], float))\n",
    "\n",
    "            LogLikelihood = 0\n",
    "\n",
    "            for Obs in Obs_seq:\n",
    "                if debug:\n",
    "                    print(\"\\nThe observation sequence is \" + str(Obs))\n",
    "                # log_prob1, Alpha1, c1 = self.forward(Obs, scaling=True, debug=False)\n",
    "\n",
    "                log_prob, Alpha, c = self.forward(Obs, scaling=True, debug=False)\n",
    "                LogLikelihood += log_prob\n",
    "                # print \"Log Likelihood is \" + str(LogLikelihood)\n",
    "\n",
    "                Beta = self.backward(Obs, scaling=True, debug=False)\n",
    "\n",
    "                if debug:\n",
    "                    print(\"\\nAlpha:\")\n",
    "                    print(Alpha)\n",
    "                    print(\"\\nBeta:\")\n",
    "                    print(Beta)\n",
    "                    print(len(Beta[0]))\n",
    "\n",
    "                T = len(Obs)\n",
    "\n",
    "                observation = []\n",
    "                # The observation sequence using observation symbol notations. It is a list [\"1\",\"1\",\"0\",\"1\"]\n",
    "                for i in range(self.n_elements):\n",
    "                    observation.append(self.obs_index([each[i] for each in Obs], i))\n",
    "\n",
    "                #### Calculate Gamma ####\n",
    "                # Gamma is defined as the probability of\n",
    "                # being in State Si at time t, given the observation sequence\n",
    "                # O1, O2, O3, O4 ,....,Ot, and the model parameters\n",
    "\n",
    "                raw_Gamma = Alpha * Beta\n",
    "                Gamma = raw_Gamma / raw_Gamma.sum(0)\n",
    "                if debug:\n",
    "                    print(\"\\nGamma\")\n",
    "                    print(Gamma)\n",
    "\n",
    "                exp_si_t0 += Gamma[:, 0]\n",
    "                exp_num_from_Si += Gamma[:, :T - 1].sum(1)\n",
    "                exp_num_in_Si += Gamma.sum(1)\n",
    "\n",
    "                # The probability in state Si having Observation Oj\n",
    "                for i in range(self.n_elements):\n",
    "\n",
    "                    temp = numpy.zeros([self.N, self.M[i]], float)\n",
    "                    for each in self.symbol_map[i].keys():\n",
    "                        which = numpy.array([self.symbol_map[i][each] == int(x) for x in observation[i]])\n",
    "                        temp[:, self.symbol_map[i][each]] = Gamma.T[which, :].sum(0)\n",
    "\n",
    "                    exp_num_in_Si_Vk[i] += temp\n",
    "\n",
    "                if debug:\n",
    "                    print(\"\\nExpected frequency in state S_i at time 0:\\n\" + str(exp_si_t0))\n",
    "                    print(\"Expected number of transition from state S_i:\\n\" + str(exp_num_from_Si))\n",
    "                    print(\"Expected number of time in state S_i:\\n\" + str(exp_num_in_Si))\n",
    "                    print(\"Expected number of time in state S_i observing V_k:\\n\" + str(exp_num_in_Si_Vk))\n",
    "\n",
    "                # Xi is defined as given the model and sequence, the probability of being in state Si at time t,\n",
    "                # and in state Sj at time t+1\n",
    "\n",
    "                Xi = numpy.zeros([T - 1, self.N, self.N], float)\n",
    "\n",
    "                for t in range(T - 1):\n",
    "                    for i in range(self.N):\n",
    "                        Xi[t, i, :] = Alpha[i, t] * self.T[i, :]\n",
    "                        for j in range(self.n_elements):\n",
    "                            Xi[t, i, :] *= self.E[j][:, int(observation[j][t + 1])]\n",
    "                        Xi[t, i, :] *= Beta[:, t + 1]\n",
    "                    Xi[t, :, :] /= Xi[t, :, :].sum()\n",
    "\n",
    "                for t in range(T - 2):\n",
    "                    exp_num_Si_Sj += Xi[t, :, :]\n",
    "\n",
    "                if debug:\n",
    "                    print(\"\\nExpected number of transitions from state Si to state Sj: \\n\" + str(exp_num_Si_Sj))\n",
    "\n",
    "            # reestimate initial state probabilities\n",
    "            if updatePi:\n",
    "                self.Pi = exp_si_t0 / exp_si_t0.sum()\n",
    "                if debug:\n",
    "                    print(\"\\nUpdated Pi:\")\n",
    "                    print(exp_si_t0)\n",
    "\n",
    "            if updateT:\n",
    "                T_hat = numpy.zeros([self.N, self.N], float).reshape(self.N, self.N)\n",
    "                for i in range(self.N):\n",
    "                    T_hat[i, :] = exp_num_Si_Sj[i, :] / exp_num_from_Si[i]\n",
    "                    T_hat[i, :] /= T_hat[i, :].sum()\n",
    "                self.T = T_hat\n",
    "\n",
    "                if debug:\n",
    "                    print(\"\\nUpdated T\")\n",
    "                    print(self.T)\n",
    "\n",
    "            if updateE:\n",
    "                for j in range(self.n_elements):\n",
    "                    E_hat = numpy.zeros([self.N, self.M[j]], float).reshape(self.N, self.M[j])\n",
    "                    for i in range(self.N):\n",
    "                        E_hat[i, :] = exp_num_in_Si_Vk[j][i, :] / exp_num_in_Si[i]\n",
    "                        E_hat[i, :] /= E_hat[i, :].sum()\n",
    "                    self.E[j] = E_hat\n",
    "                    if debug:\n",
    "                        print(\"\\nUpdated E\")\n",
    "                        print(self.E)\n",
    "            print(LogLikelihood)\n",
    "            LLS.append(LogLikelihood)\n",
    "            if epoch > 1:\n",
    "                if abs(LLS[epoch] - LLS[epoch - 1]) < epsilon:\n",
    "                    print(\"The loglikelihood improvement falls below threshold, training terminates at epoch \" + str(\n",
    "                        epoch) + \"! \")\n",
    "                    break\n",
    "\n",
    "        self._print_HMM(\"After training\")\n",
    "        return\n",
    "        \n",
    "    # predict knowledge component learning score , --> P(Ln)\n",
    "    def predict_nlg(self, Obs_seq, debug=False):\n",
    "        nlg_scores = []\n",
    "        for Obs in Obs_seq:\n",
    "            if debug:\n",
    "                print(\"\\nThe observation sequence is \" + str(Obs))\n",
    "            if Obs:\n",
    "                log_prob, Alpha, c = self.forward(Obs, scaling=True, debug=False)\n",
    "                # print \"Posttest score:\"\n",
    "                # print round(Alpha[:, -1][1], 2)\n",
    "                # nlg = round(Alpha[:, -1][1], 2)\n",
    "                nlg = Alpha[:, -1][1]\n",
    "            else:\n",
    "                nlg = 0\n",
    "            nlg_scores.append(nlg)\n",
    "            # print \"NLG Score:\" + str(round(Alpha[:, -1][1], 2) - hmm.Pi[0])\n",
    "        return nlg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************\n",
      "HMM Initialization\n",
      "************************\n",
      "\n",
      "1) Numerber of hidden states:2\n",
      "2) Number of observable symbols:[['0', '1']]\n",
      "3) The symbol mapping in HMM:[{'0': 0, '1': 1}]\n",
      "4) The transmission proability matrix T:\n",
      "[[0.8 0.2]\n",
      " [0.1 0.9]]\n",
      "5) The emission probability matrix E:\n",
      "[array([[0.7659189 , 0.2340811 ],\n",
      "       [0.28152715, 0.71847285]])]\n",
      "6) The initial state probability Pi: \n",
      "[0.8 0.2]\n",
      "\n",
      "Epoch 0\n",
      "-1973.837466489232\n",
      "Epoch 1\n",
      "-1969.1632431258265\n",
      "Epoch 2\n",
      "-1967.2353719460039\n",
      "Epoch 3\n",
      "-1965.766463756864\n",
      "Epoch 4\n",
      "-1964.6022147768822\n",
      "Epoch 5\n",
      "-1963.6514411007602\n",
      "Epoch 6\n",
      "-1962.8578178319424\n",
      "Epoch 7\n",
      "-1962.1837494184108\n",
      "Epoch 8\n",
      "-1961.6023569989445\n",
      "Epoch 9\n",
      "-1961.0937334592152\n",
      "Epoch 10\n",
      "-1960.6429593711348\n",
      "Epoch 11\n",
      "-1960.2388429658824\n",
      "Epoch 12\n",
      "-1959.873006352535\n",
      "Epoch 13\n",
      "-1959.5391834017184\n",
      "Epoch 14\n",
      "-1959.232674400823\n",
      "Epoch 15\n",
      "-1958.9499263763125\n",
      "Epoch 16\n",
      "-1958.6882152582136\n",
      "Epoch 17\n",
      "-1958.4454094300715\n",
      "Epoch 18\n",
      "-1958.2197970056104\n",
      "Epoch 19\n",
      "-1958.009961970439\n",
      "Epoch 20\n",
      "-1957.8146970375872\n",
      "Epoch 21\n",
      "-1957.6329435406176\n",
      "Epoch 22\n",
      "-1957.4637508387366\n",
      "Epoch 23\n",
      "-1957.3062495066515\n",
      "Epoch 24\n",
      "-1957.1596340396159\n",
      "Epoch 25\n",
      "-1957.023151956028\n",
      "Epoch 26\n",
      "-1956.8960970683697\n",
      "Epoch 27\n",
      "-1956.7778053651682\n",
      "Epoch 28\n",
      "-1956.6676524432805\n",
      "Epoch 29\n",
      "-1956.5650517900174\n",
      "Epoch 30\n",
      "-1956.4694534701043\n",
      "Epoch 31\n",
      "-1956.3803429491597\n",
      "Epoch 32\n",
      "-1956.2972399048024\n",
      "Epoch 33\n",
      "-1956.2196969540817\n",
      "Epoch 34\n",
      "-1956.1472982746402\n",
      "Epoch 35\n",
      "-1956.0796581253412\n",
      "Epoch 36\n",
      "-1956.0164192873385\n",
      "Epoch 37\n",
      "-1955.9572514529336\n",
      "Epoch 38\n",
      "-1955.9018495905955\n",
      "Epoch 39\n",
      "-1955.8499323125773\n",
      "Epoch 40\n",
      "-1955.8012402679954\n",
      "Epoch 41\n",
      "-1955.7555345800008\n",
      "Epoch 42\n",
      "-1955.7125953414013\n",
      "Epoch 43\n",
      "-1955.6722201793057\n",
      "Epoch 44\n",
      "-1955.6342228957647\n",
      "Epoch 45\n",
      "-1955.5984321885812\n",
      "Epoch 46\n",
      "-1955.5646904540256\n",
      "Epoch 47\n",
      "-1955.5328526714127\n",
      "Epoch 48\n",
      "-1955.5027853678173\n",
      "Epoch 49\n",
      "-1955.4743656605533\n",
      "Epoch 50\n",
      "-1955.4474803738233\n",
      "Epoch 51\n",
      "-1955.422025225825\n",
      "Epoch 52\n",
      "-1955.3979040820632\n",
      "Epoch 53\n",
      "-1955.3750282706453\n",
      "Epoch 54\n",
      "-1955.3533159551514\n",
      "Epoch 55\n",
      "-1955.332691560977\n",
      "Epoch 56\n",
      "-1955.313085250858\n",
      "Epoch 57\n",
      "-1955.2944324458208\n",
      "Epoch 58\n",
      "-1955.2766733877656\n",
      "Epoch 59\n",
      "-1955.2597527401676\n",
      "Epoch 60\n",
      "-1955.2436192236892\n",
      "Epoch 61\n",
      "-1955.2282252836792\n",
      "Epoch 62\n",
      "-1955.213526786699\n",
      "Epoch 63\n",
      "-1955.1994827435938\n",
      "Epoch 64\n",
      "-1955.1860550566703\n",
      "Epoch 65\n",
      "-1955.1732082888668\n",
      "Epoch 66\n",
      "-1955.1609094528976\n",
      "Epoch 67\n",
      "-1955.1491278186083\n",
      "Epoch 68\n",
      "-1955.1378347368614\n",
      "Epoch 69\n",
      "-1955.127003478487\n",
      "Epoch 70\n",
      "-1955.1166090869258\n",
      "Epoch 71\n",
      "-1955.1066282433028\n",
      "Epoch 72\n",
      "-1955.097039142881\n",
      "Epoch 73\n",
      "-1955.087821381791\n",
      "Epoch 74\n",
      "-1955.07895585318\n",
      "Epoch 75\n",
      "-1955.07042465191\n",
      "Epoch 76\n",
      "-1955.062210987041\n",
      "Epoch 77\n",
      "-1955.054299101462\n",
      "Epoch 78\n",
      "-1955.0466741979349\n",
      "Epoch 79\n",
      "-1955.0393223711212\n",
      "Epoch 80\n",
      "-1955.0322305449822\n",
      "Epoch 81\n",
      "-1955.0253864150943\n",
      "Epoch 82\n",
      "-1955.0187783955034\n",
      "Epoch 83\n",
      "-1955.012395569688\n",
      "Epoch 84\n",
      "-1955.006227645291\n",
      "Epoch 85\n",
      "-1955.000264912309\n",
      "Epoch 86\n",
      "-1954.9944982044594\n",
      "Epoch 87\n",
      "-1954.988918863421\n",
      "Epoch 88\n",
      "-1954.9835187057706\n",
      "Epoch 89\n",
      "-1954.978289992327\n",
      "Epoch 90\n",
      "-1954.9732253997686\n",
      "Epoch 91\n",
      "-1954.9683179942913\n",
      "Epoch 92\n",
      "-1954.9635612071725\n",
      "Epoch 93\n",
      "-1954.9589488120785\n",
      "Epoch 94\n",
      "-1954.954474903985\n",
      "Epoch 95\n",
      "-1954.950133879562\n",
      "Epoch 96\n",
      "-1954.9459204189393\n",
      "Epoch 97\n",
      "-1954.9418294687162\n",
      "Epoch 98\n",
      "-1954.9378562261652\n",
      "Epoch 99\n",
      "-1954.9339961244614\n",
      "\n",
      "\n",
      "************************\n",
      "After training\n",
      "************************\n",
      "\n",
      "1) Numerber of hidden states:2\n",
      "2) Number of observable symbols:[['0', '1']]\n",
      "3) The symbol mapping in HMM:[{'0': 0, '1': 1}]\n",
      "4) The transmission proability matrix T:\n",
      "[[0.93678598 0.06321402]\n",
      " [0.00470168 0.99529832]]\n",
      "5) The emission probability matrix E:\n",
      "[array([[0.70087843, 0.29912157],\n",
      "       [0.29890552, 0.70109448]])]\n",
      "6) The initial state probability Pi: \n",
      "[0.8 0.2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bkt.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score, roc_auc_score, mean_squared_error\n",
    "# fast-correct, fast-incorrect, slow-correct, slow-incorrect\n",
    "# symbols = [['0', '1','2','3']]\n",
    "# correct, incorrect\n",
    "symbols = [['0', '1']]\n",
    "train_X = np.load('./bkt/new_bkt_pertime_kc2.npy',allow_pickle=True)\n",
    "\n",
    "train = [ [y if y in ['0','1'] else '0' if y=='2' else '1' for y in x]   for x in train_X if x]\n",
    "\n",
    "h = hmm(2, Pi=np.array([0.8, 0.2]), T=np.array([[0.8, 0.2], [0.1, 0.9]]), obs_symbols=symbols)\n",
    "h.baum_welch(train, epochs=100, debug=False,updatePi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "code_folding": [
     8,
     12,
     36
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The observation sequence is ['1', '0', '0', '0']\n",
      "scores --> [0.8284466544149486]\n",
      "{'N': 2, 'V': [['0', '1']], 'M': [2], 'n_elements': 1, 'symbol_map': [{'0': 0, '1': 1}], 'T': array([[0.99108215, 0.00891785],\n",
      "       [0.06576657, 0.93423343]]), 'E': [array([[0.34376234, 0.65623766],\n",
      "       [0.74021118, 0.25978882]])], 'Pi': array([0.33783612, 0.66216388])}\n",
      "[0.33783612 0.66216388]\n",
      "[0, 0, 1, 0, 1, 0, 0, 0, 1, 0, -1]\n",
      "pred  -->[[0.61901121 0.38098879]]\n",
      "pred_observ --> [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "alpha --> [[0.19155508 0.12974642 0.36569517 0.23954278 0.50467551 0.34619783\n",
      "  0.22606183 0.14973756 0.39344617 0.25931418 0.16977555]\n",
      " [0.80844492 0.87025358 0.63430483 0.76045722 0.49532449 0.65380217\n",
      "  0.77393817 0.85026244 0.60655383 0.74068582 0.83022445]]\n",
      "score --> 0.830224452788321\n"
     ]
    }
   ],
   "source": [
    "# 学习掌握情况分析, 预测\n",
    "# 学习情况 P(Ln-1|action=correct) = P(Ln-1) * (1-P(S)) / P(Ln-1) * (1-P(S))  + (1-P(ln-1)) * P(G)\n",
    "#         P(Ln|action) = P(Ln-1|action) + ((1-P(Ln-1|action))) * P(T)\n",
    "\n",
    "'''\n",
    "alpha 学习掌握情况概率\n",
    "alpha = np.zeros((states,T))  states=2, T=observation length=5\n",
    "pi = [0.2,0.8]\n",
    "alpha[:,0]=pi  ===> array([[0.2, 0. , 0. , 0. , 0. ],\n",
    "                           [0.8, 0. , 0. , 0. , 0. ]])\n",
    "E ==> (states, observation symboles length)  ==> np.randin((2,4))\n",
    "\n",
    "observertion[0] = 1 (观察状态第一位为1) ==> alpha[:,0] = alpha[:,0] * e[:,1]  ==> [0,2,0.8] * [0.1,0.3]\n",
    "                                    ==>  alpha = array([[0.12, 0. , 0. , 0. , 0. ],\n",
    "                                                        [0.88, 0. , 0. , 0. , 0. ]])\n",
    "                                                        \n",
    "P(action=correct|Ln-1) = P(Ln-1) * (1-P(S)) / P(Ln-1) * (1-P(S))  + (1-P(ln-1)) * P(G)\n",
    "P(Ln|action) = P(Ln-1|action) + ((1-P(Ln-1|action))) * P(T)\n",
    "'''\n",
    "import numpy as np\n",
    "# guess, slip  guess,  slip\n",
    "'''       cor    err\n",
    "know      1-S     S\n",
    "unknow     G     1-G\n",
    "'''\n",
    "# 得分\n",
    "student = [['1','0','0','0']]\n",
    "scores = h.predict_nlg(student, debug=True)\n",
    "print('scores -->' ,scores)\n",
    "\n",
    "# 预测\n",
    "print(h.__dict__)\n",
    "print(h.Pi)\n",
    "# 预测答题正确，  observ: 当前观察值，  p_num 需预测下面的正确情况\n",
    "# fast-correct, fast-incorrect, slow-correct, slow-incorrect\n",
    "# symbols = [['0', '1', '2', '3']]\t\n",
    "def predict_correct(hmm, observ, p_num=3):\n",
    "    pred_values = np.zeros([len(observ)+p_num, len(h.V[0])],float)\n",
    "    pred_observ = np.zeros([1, len(observ) + p_num],int)\n",
    "    pred_observ -= 1\n",
    "    pred_observ = pred_observ.tolist()[0]\n",
    "    if len(observ) > 0:\n",
    "        pred_observ[0:len(observ)] = observ\n",
    "    print(pred_observ)\n",
    "    \n",
    "    alpha = np.zeros([h.N,len(observ)+p_num], float)  # states(2) * T  array\n",
    "    alpha[:,0] = hmm.Pi\n",
    "    if pred_observ[0] == -1:\n",
    "        # 当前观值无，需预测\n",
    "        pred = np.dot(alpha[:,0].reshape(1,2), hmm.E[0]) # PI  dot E(State) ==> (1,2) dot (2, 4(observ state))\n",
    "        pred_observ[0] = np.argmax(pred, axis=1)[0]                 # output ==> (1, 4)\n",
    "        \n",
    "    \n",
    "    alpha[:,0] *= hmm.E[0][:, pred_observ[0]]   # PI (0.8 L, 0.2 UL) * E(state(L,UN), ObservState)   \n",
    "    alpha[:,0] = alpha[:,0] / alpha[:,0].sum()\n",
    "    \n",
    "    #     print(alpha[:,0])\n",
    "    for t in range(1, len(pred_observ)):\n",
    "        alpha[:,t] = np.dot(alpha[:,t-1], hmm.T)\n",
    "#         print('t :{}, alpha {}'.format(t, alpha))\n",
    "        if pred_observ[t] == -1:\n",
    "            pred = np.dot(alpha[:,t].reshape(1,2), hmm.E[0])\n",
    "            print('pred  -->{}'.format(pred/pred.sum()))\n",
    "            pred_observ[t] = np.argmax(pred, axis=1)[0]\n",
    "        alpha[:,t] *= hmm.E[0][:, pred_observ[t]]\n",
    "        alpha[:,t] = alpha[:,t]/ alpha[:,t].sum()\n",
    "        \n",
    "    \n",
    "    print('pred_observ -->', pred_observ)\n",
    "    print('alpha -->', alpha)\n",
    "    print('score -->', alpha[:,-1][1])\n",
    "    \n",
    "#     P = np.dot(alpha[:,0], hmm.E[0])\n",
    "#     pred_values[0] = P\n",
    "    \n",
    "#     alpha[:,0] = alpha[:,0]/alpha[:,0].sum()\n",
    "    \n",
    "#     for t in range(1,len(observ)+p_num):\n",
    "#         alpha[:,t] = np.dot(alpha[:,t-1], h.T)\n",
    "#         alpha[:, t] =  np.dot(alpha[:,t], hmm.E[0])\n",
    "#         alpha[:, t] = alpha[:, t] / alpha[:, t].sum()\n",
    "#         pred_values[t] = alpha[:, t]\n",
    "    \n",
    "#     print('alpha -->',alpha)\n",
    "#     print('pred values -->',pred_values, ' 最大可能:', np.argmax(pred_values, axis=1))\n",
    "    \n",
    "predict_correct(h, observ=[0,0,1,0,1,0,0,0,1,0], p_num=1)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
