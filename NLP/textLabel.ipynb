{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.data.dataset as ds\n",
    "import importlib\n",
    "from torch.utils import data\n",
    "importlib.reload(ds)\n",
    "import torch.nn as nn\n",
    "from easydict import EasyDict as edict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "房产 房产\n",
      "股票 股票\n",
      "教育 教育\n",
      "彩票 彩票\n",
      "财经 财经\n",
      "家居 家居\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# data_path = 'D:/PROJECT_TW/git/data/nlp/w2v/data/'\n",
    "# model_path = 'D:/PROJECT_TW/git/data/nlp/w2v/'\n",
    "model_path = '/home/hecong/temp/data/txtdect/'\n",
    "data_path = '/home/hecong/temp/data/txtdect/data/'\n",
    "eds = ds.EduData(data_path, model_path)\n",
    "dl = data.DataLoader(eds,batch_size=50,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 64])\n"
     ]
    }
   ],
   "source": [
    "#检测 nn.Emmeding 使用训练好的词向量结果\n",
    "import torch.nn as nn\n",
    "_,in_data = next(enumerate(dl))\n",
    "words, labels = in_data\n",
    "print(words.size())\n",
    "embedding_matrix = torch.from_numpy(eds.embedding_matrix)\n",
    "embed = nn.Embedding(40000, 20,_weight=embedding_matrix)\n",
    "out_data = embed(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1263,  0.0895,  0.1022, -0.0152, -0.0142, -0.1604,  0.0136,  0.2782,\n",
      "         0.1092,  0.3852,  0.0381, -0.1342, -0.0961, -0.3812,  0.1454, -0.0697,\n",
      "         0.2485,  0.3764,  0.2450,  0.1813],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "tensor([ 7716,  8260,  9889,  3648,  6989, 10345,  2932,  2932,  2932,  2932,\n",
      "         2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,\n",
      "         2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,\n",
      "         2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,\n",
      "         2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,\n",
      "         2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,  2932,\n",
      "         2932,  2932,  2932,  2932])\n",
      "桥往\n",
      "[-0.09392507  0.07842945  0.08145787 -0.06175676 -0.01244122 -0.15300395\n",
      "  0.00825114  0.26267716  0.12067892  0.3600079   0.05808657 -0.11769318\n",
      " -0.05155514 -0.31181234  0.12862869 -0.05610953  0.19461681  0.33628106\n",
      "  0.21073024  0.18801825]\n"
     ]
    }
   ],
   "source": [
    "print(out_data[0][5])\n",
    "print(words[0])\n",
    "print(eds.idx_to_word[4237])\n",
    "print(eds.word_vec_mod.wv.get_vector('布莱克本'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 初始化参数\n",
    "opt =  edict()\n",
    "opt.vocab_size = 40000\n",
    "opt.embedding_dim = 20\n",
    "opt.inception_dim = 40\n",
    "opt.static = False\n",
    "opt.num_classes = 6\n",
    "opt.content_seq_len = 64\n",
    "opt.linear_hidden_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 关于conv1D 参看： https://blog.csdn.net/sunny_xsc1994/article/details/82969867\n",
    "import lib.models.CNNText_inception as cni\n",
    "import torch\n",
    "import os\n",
    "importlib.reload(cni)\n",
    "model_path = '/home/hecong/temp/data/txtdect/text_label_model.pkl'\n",
    "embedding_matrix = torch.from_numpy(eds.embedding_matrix)\n",
    "model = cni.CNNText_inception(opt, embedding_matrix)\n",
    "# 注意下面这个， 将model设置成model.double\n",
    "# https://stackoverflow.com/questions/49407303/runtimeerror-expected-object-of-type-torch-doubletensor-but-found-type-torch-fl\n",
    "model = model.double()\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 0 loss -->  0.16328241401315668 \n",
      "0 - 20 loss -->  0.05633893977000484 \n",
      "0 - 40 loss -->  0.26951541884198543 \n",
      "1 - 0 loss -->  0.12244422631829163 \n",
      "1 - 20 loss -->  0.06169934083270395 \n",
      "1 - 40 loss -->  0.1322342433980609 \n",
      "2 - 0 loss -->  0.11293894033177489 \n",
      "2 - 20 loss -->  0.09090075843086266 \n",
      "2 - 40 loss -->  0.15550820445095412 \n",
      "3 - 0 loss -->  0.1764132696415878 \n",
      "3 - 20 loss -->  0.12626639566555078 \n",
      "3 - 40 loss -->  0.18832226897916585 \n",
      "4 - 0 loss -->  0.032558019594395866 \n",
      "4 - 20 loss -->  0.07329850720954112 \n",
      "4 - 40 loss -->  0.121924726046223 \n",
      "5 - 0 loss -->  0.07428776664816882 \n",
      "5 - 20 loss -->  0.2830046885585898 \n",
      "5 - 40 loss -->  0.1376136573303242 \n",
      "6 - 0 loss -->  0.15969451648023142 \n",
      "6 - 20 loss -->  0.12167635734823863 \n",
      "6 - 40 loss -->  0.10387805624821288 \n",
      "7 - 0 loss -->  0.15330603433696463 \n",
      "7 - 20 loss -->  0.12172527835127418 \n",
      "7 - 40 loss -->  0.11771297107651428 \n",
      "8 - 0 loss -->  0.121118666147443 \n",
      "8 - 20 loss -->  0.07305324908084934 \n",
      "8 - 40 loss -->  0.13953691067651455 \n",
      "9 - 0 loss -->  0.08746598598852953 \n",
      "9 - 20 loss -->  0.0902652026657344 \n",
      "9 - 40 loss -->  0.06309472739793226 \n",
      "10 - 0 loss -->  0.26916841568792926 \n",
      "10 - 20 loss -->  0.12235468172795504 \n",
      "10 - 40 loss -->  0.05500559882725481 \n",
      "11 - 0 loss -->  0.1032662657964371 \n",
      "11 - 20 loss -->  0.08209580902412285 \n",
      "11 - 40 loss -->  0.03785591084133797 \n",
      "12 - 0 loss -->  0.02296382833570812 \n",
      "12 - 20 loss -->  0.11002733796186112 \n",
      "12 - 40 loss -->  0.09455927822990302 \n",
      "13 - 0 loss -->  0.08259106551444004 \n",
      "13 - 20 loss -->  0.08187446227130614 \n",
      "13 - 40 loss -->  0.08651192906985003 \n",
      "14 - 0 loss -->  0.06952579485151937 \n",
      "14 - 20 loss -->  0.04598063369419712 \n",
      "14 - 40 loss -->  0.06448709628465926 \n",
      "15 - 0 loss -->  0.18110912534102552 \n",
      "15 - 20 loss -->  0.05979493952168647 \n",
      "15 - 40 loss -->  0.13959645861737105 \n",
      "16 - 0 loss -->  0.05837388652908105 \n",
      "16 - 20 loss -->  0.08841568387493426 \n",
      "16 - 40 loss -->  0.02520006012928265 \n",
      "17 - 0 loss -->  0.048880308229228675 \n",
      "17 - 20 loss -->  0.06489790592136212 \n",
      "17 - 40 loss -->  0.0735006028456108 \n",
      "18 - 0 loss -->  0.06964176428946996 \n",
      "18 - 20 loss -->  0.05718803713043427 \n",
      "18 - 40 loss -->  0.08902301464363706 \n",
      "19 - 0 loss -->  0.11633891955798552 \n",
      "19 - 20 loss -->  0.057285483873696114 \n",
      "19 - 40 loss -->  0.051562858942923694 \n",
      "20 - 0 loss -->  0.04010402667030874 \n",
      "20 - 20 loss -->  0.02899840326442484 \n",
      "20 - 40 loss -->  0.11276210264203831 \n",
      "21 - 0 loss -->  0.1030911123053662 \n",
      "21 - 20 loss -->  0.06900086402870959 \n",
      "21 - 40 loss -->  0.06678513075361693 \n",
      "22 - 0 loss -->  0.14148873132787565 \n",
      "22 - 20 loss -->  0.03759730547469701 \n",
      "22 - 40 loss -->  0.03006878627007018 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-07c078e1125a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPCHO = 100\n",
    "loss_fun =  nn.CrossEntropyLoss()\n",
    "\n",
    "LR = 0.001\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "MOMENTUM = 0.9\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=LR, momentum=MOMENTUM)\n",
    "\n",
    "for step in range(EPCHO):\n",
    "    for i, (words, labels) in enumerate(dl):\n",
    "        out = model(content=words)\n",
    "        loss = loss_fun(out,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 20 == 0:\n",
    "            print('{} - {} loss -->  {} '.format(step,i, loss))\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别 --> 财经\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "testDoc = '''\n",
    "    中国2010年棉花产量预计减少5.5%\n",
    "　　新浪财经讯 11月18日下午消息，来自国资委网站消息，中国储备棉管理总公司周四发布报告称，由于遭遇恶劣天气，预计今年全国棉花种植总产量636.0万吨，减少5.5%。\n",
    "　　2010年10月下旬至11月上旬，中国储备棉管理总公司承建的国家棉花市场监测系统对2010年度我国棉花产量情况在全国范围内展开调查，涉及15个植棉省(自治区)、87个植棉县(市、团场)。\n",
    "　　结果显示，由于今年棉花播种期遭受低温、吐絮期遭遇连续强降雨等灾害天气，棉花质量和产量均受到不利影响。今年全国棉花种植面积7568.2万亩，较上年减少1.1%；单产84.0公斤/亩，下降4.4%；总产量636.0万吨，减少5.5%。\n",
    "　　该项统计数为初步预计结果，报告呼吁棉花产业各环节对棉花产量和供求格局有清醒认识，克服投机心理，谨慎经营，控制风险。 \n",
    "'''    \n",
    "# 提取中文, 分词， 得到词向量\n",
    "line = ds.extract_chinese(testDoc)\n",
    "ws = jieba.lcut(line, cut_all=False, HMM=True)\n",
    "words_ids = [eds.word_to_idx[x] for x in ws if x in eds.word_to_idx]\n",
    "words_ids = words_ids[0:64]\n",
    "words_ids = torch.LongTensor(words_ids)\n",
    "words_ids = words_ids.unsqueeze(0)\n",
    "twords = words[0]\n",
    "twords = twords.unsqueeze(0)\n",
    "model.eval()\n",
    "out = model(content=words_ids)\n",
    "print('类别 --> {}'.format(eds.index_lables[torch.argmax(out).item()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
